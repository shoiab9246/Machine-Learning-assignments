{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework  Task\n",
    "\n",
    "In module 9 we learned how to solve a problem from end to end using SKLearn and pipelines. There we learned how to  predict house prices in California.\n",
    "In this homework, we adopt this end to end pipeline to tackle the Titanic Survival problem.\n",
    "Adopt the machine learning pipeline above to tackle the Titanic problem. \n",
    "## Submission instructions\n",
    "1. Before completing this homework,\n",
    "    * please review this homework's submission form on Canvas available under the \"Modules\" menu option and \n",
    "    * briefly review this notebook end to end. \n",
    "* To get you started we provide a template solution with missing code and prompts. Please complete the missing code, run the experiments and log your results.\n",
    "* When you're sufficiently happy with your results, please begin the submission process on Canvas. Use the submission form for this homework available under \"Modules\" menu option. Please note that the submission form is available at the same place where you downloaded the homework from.\n",
    "* You may wish to reference this quiz while working through the tasks.\n",
    "\n",
    "You will need to:\n",
    "\n",
    "* __Important:__ To ensure the accuracy of your results (for the quiz) you must split the data using a 20% test set with random seed = 42.\n",
    "* __EDA.__ Identify the types of data available, evaluate basic statistical information about the data and determine whether you have any missing or misformated data.\n",
    "\n",
    "* __Feature Engineering.__  Develop at least one new feature.  The following [webpage](http://trevorstephens.com/kaggle-titanic-tutorial/r-part-4-feature-engineering/) has some great ideas for creating new features on the Titanic dataset.\n",
    "* __Pre-processing.__  All work must be performed using pipelines.  You can adapt code from above or develop your own.\n",
    "* __Modeling.__Evaluate at least two appropriate algorithms (estimators) for generating predictions.\n",
    "    * Use grid search to tune hyperparameters.\n",
    "    * Use crossfold evaluation (cv=5).\n",
    "* __Evaluation.__ Select appropriate metrics for the problem to evaluate your models.\n",
    "* __Reporting.__ Record all experiments in a table of results (pandas dataframe) including at least the following information:  \n",
    "    * description of the model (algorithim, notable processing steps) \n",
    "    * key hyperparameters\n",
    "    * results (using one or more appropriate metrics)\n",
    "    * run time for each experiment (train and test results)\n",
    "    * hardware used\n",
    "* __Analysis__. Perform a significance test on your best models and discuss results (see Module 09.5 in Canvas for a video lecture on significance testing).\n",
    "\n",
    "Your final pipeline will take the following format:\n",
    "\n",
    "<PRE>\n",
    "full_pipeline_with_predictor = Pipeline([\n",
    "        (\"preparation\", full_pipeline),  # combination of numerical and categorical pipelines\n",
    "        (\"logRegression\", LogisticRegression())  # replace with whatever estimator(s) you are using\n",
    "    ])\n",
    "\n",
    "</PRE>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the notebook (imports, helper functions, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T00:16:15.867443Z",
     "start_time": "2018-11-09T00:16:11.144352Z"
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "from time import time\n",
    "from scipy import stats\n",
    "import json\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T00:16:15.879776Z",
     "start_time": "2018-11-09T00:16:15.875989Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a class to select numerical or categorical columns \n",
    "# since Scikit-Learn doesn't handle DataFrames yet\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T00:16:15.948484Z",
     "start_time": "2018-11-09T00:16:15.889730Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports for metrics\n",
    "from sklearn.model_selection import cross_val_score, ShuffleSplit\n",
    "# Imports for stats\n",
    "from scipy import stats\n",
    "                       \n",
    "# Convert a number to a percent.    \n",
    "def pct(x):\n",
    "    return round(100*x,1)\n",
    "\n",
    "# Set up reporting\n",
    "import pandas as pd\n",
    "results = pd.DataFrame(columns=[\"ExpID\", \"Cross fold train accuracy\", \"Test Accuracy\", \"p-value\", \"Train Time(s)\", \"Test Time(s)\", \"Experiment description\"])\n",
    "\n",
    "# Set up ShuffleSplit for p_value testing\n",
    "cv = ShuffleSplit(n_splits=30, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T00:16:15.964536Z",
     "start_time": "2018-11-09T00:16:15.960033Z"
    }
   },
   "outputs": [],
   "source": [
    "def ttest(control, treatment):\n",
    "    #paired t-test; two-tailed p-value      A   ,    B\n",
    "    (t_score, p_value) = stats.ttest_rel(control, treatment)\n",
    "\n",
    "    if p_value > 0.05/2:  #Two sided \n",
    "        print('There is no significant difference between the two machine learning pipelines (Accept H0)')\n",
    "    else:\n",
    "        print('The two machine learning pipelines are different (reject H0) \\n(t_score, p_value) = (%.2f, %.5f)'%(t_score, p_value) )\n",
    "        if t_score > 0.0: #in the case of regression lower RMSE is better; A is lower \n",
    "            print('Machine learning pipeline A is better than B')\n",
    "        else:\n",
    "            print('Machine learning pipeline B is better than A')\n",
    "    return p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data import and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T00:16:15.988448Z",
     "start_time": "2018-11-09T00:16:15.973642Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('datasets/titanic/train.csv')\n",
    "y = data['Survived']\n",
    "x = data.drop(['Survived', 'Ticket', 'Cabin'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T00:16:16.039694Z",
     "start_time": "2018-11-09T00:16:16.025594Z"
    }
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T00:16:16.090140Z",
     "start_time": "2018-11-09T00:16:16.080622Z"
    }
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your code here to find attribute with most null values. \n",
    "#==================================================#\n",
    "#               Your code starts here              #\n",
    "#==================================================#\n",
    "\n",
    "#==================================================#\n",
    "#               Your code ends here                #\n",
    "#               Please don't add code below here   #\n",
    "#==================================================#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T00:16:16.165817Z",
     "start_time": "2018-11-09T00:16:16.127612Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T00:16:16.215163Z",
     "start_time": "2018-11-09T00:16:16.206634Z"
    }
   },
   "outputs": [],
   "source": [
    "# Show the correlation of the Survived column with the features\n",
    "corr_matrix = data.corr()\n",
    "corr_matrix[\"Survived\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Observations\n",
    "The goal of this section is to get familiar with the data that will be used for the end to end pipeline. It is very important to explore the data and summarize its main characteristics before diving in the machine learning models. It is also interesting to see how the different features are correlated with the target feature\n",
    "\n",
    "* *Fare* and *Pclass* are the most highly correlated with survivorship. A higher fare indicates a higher chance of surviving; a lower class (where \"first\" class is better than \"third\") indicates a higher chance of survinging. \n",
    "* *Sex* and *Embarked* do not appear in the correlation list, because they are not numeric values. We can one-hot encode this column and re-examine later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T00:16:23.094178Z",
     "start_time": "2018-11-09T00:16:21.619001Z"
    }
   },
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "data = pd.read_csv('datasets/titanic/train.csv')\n",
    "\n",
    "# Top four correlated inputs with survived\n",
    "attributes = [\"Survived\", \"Fare\", \"Pclass\", \"Parch\", \"Age\"]\n",
    "scatter_matrix(data[attributes], figsize=(12, 8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate categorical features with respect to Survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T00:16:23.602602Z",
     "start_time": "2018-11-09T00:16:23.137106Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('datasets/titanic/train.csv')\n",
    "cat_vars = ['Sex', 'Pclass', 'Embarked']\n",
    "plt.figure(figsize=(15,4))\n",
    "for idx, cat in enumerate(cat_vars):\n",
    "    plt.subplot(1, 3, idx+1)\n",
    "    sns.countplot(data[cat], hue=data['Survived'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T00:16:25.301504Z",
     "start_time": "2018-11-09T00:16:25.290387Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "data = pd.read_csv('datasets/titanic/train.csv')\n",
    "y = data['Survived']\n",
    "x = data.drop(['Survived', 'Ticket', 'Cabin'], axis = 1)\n",
    "# split 20% test data with random seed set to 42 for correct results\n",
    "# and shuffle the dataset\n",
    "#==================================================#\n",
    "#               Your code starts here              #\n",
    "#==================================================#\n",
    "x_train, x_test, y_train, y_test = train_test_split()  \n",
    "#==================================================#\n",
    "#               Your code ends here                #\n",
    "#               Please don't add code below here   #\n",
    "#==================================================#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build processing pipelines\n",
    "In this part of the homework the focus is on constructing the pipeline. Since the data has both numerical and categorical features, it is required to create two pipelines (one for each category of data) because they require different transformations. After finishing that, the two pipelines should be unified to produce one full pipeline that performs transformation on all the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T00:16:28.833450Z",
     "start_time": "2018-11-09T00:16:28.826296Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "# Identify the numeric features we wish to consider. \n",
    "num_attribs = [\n",
    "    'Age', \n",
    "    'Parch', \n",
    "    'SibSp',\n",
    "    'Fare'\n",
    "]\n",
    "# Create a pipeline for the numeric features.\n",
    "# Use DataFrameSelector with the numeric features defined above\n",
    "# Use StandardScaler() to standardize the data\n",
    "# Missing values will be imputed using the feature median.\n",
    "#==================================================#\n",
    "#               Your code starts here              #\n",
    "#==================================================#\n",
    "num_pipeline =Pipeline()   \n",
    "#==================================================#\n",
    "#               Your code ends here                #\n",
    "#               Please don't add code below here   #\n",
    "#==================================================#\n",
    "\n",
    "\n",
    "# Identify the categorical features we wish to consider.\n",
    "cat_attribs = [\n",
    "    \"Embarked\", \n",
    "    \"Sex\",\n",
    "    \"Pclass\"\n",
    "]\n",
    "# Identiy the range of expected values for the categorical features.\n",
    "cat_values = [\n",
    "    ['S','C','Q'],     # Embarked\n",
    "    ['female','male'], # Sex\n",
    "    [1,2,3] # Pclass\n",
    "]\n",
    "# Create a pipelne for the categorical features.\n",
    "# Entries with missing values or values that don't exist in the range\n",
    "# defined above will be one hot encoded as zeroes.\n",
    "cat_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(cat_attribs)),\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('ohe', OneHotEncoder(sparse=False, handle_unknown=\"ignore\"))\n",
    "    ])\n",
    "\n",
    "# Union the transformed, scaled numeric and categorical features.\n",
    "#==================================================#\n",
    "#               Your code starts here              #\n",
    "#==================================================#\n",
    "full_pipeline = FeatureUnion()     #TODO <- ColumnTransformer\n",
    "#==================================================#\n",
    "#               Your code ends here                #\n",
    "#               Please don't add code below here   #\n",
    "#==================================================#\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "When conducting an end to end Machine Learning project, after exploring and preprocessing the data it is essential to think of feature engineering. It consists of creating new feature(s) based on the features that already exist in the dataset that can be useful for training the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Develop a new feature based on the title from each passengers name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the distribution of titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T00:16:44.678632Z",
     "start_time": "2018-11-09T00:16:44.455797Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('datasets/titanic/train.csv')\n",
    "\n",
    "data['Title'] = data['Name'].apply(lambda x: re.search(' ([A-Z][a-z]+)\\.', x).group(1))\n",
    "sns.countplot(x='Title', data=data)\n",
    "plt.title('Distribution of Titles Amongst Passengers')\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consolidate special and miscellaneous titles\n",
    "Most titles fall into one of four categories (Mr, Mrs., Miss, Master).  All other titles can be combined with one of these groups (i.e., they are French varients) or grouped as \"other\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T00:16:59.610825Z",
     "start_time": "2018-11-09T00:16:59.410019Z"
    }
   },
   "outputs": [],
   "source": [
    "data['Title'] = data['Title'].replace({'Mlle':'Miss', 'Mme':'Mrs', 'Ms':'Miss'})\n",
    "data['Title'] = data['Title'].replace(['Don', 'Dona', 'Rev', 'Dr','Major', 'Lady', 'Sir', \n",
    "                                       'Col', 'Capt', 'Countess', 'Jonkheer'],'Other')\n",
    "sns.countplot(x='Title', data=data);\n",
    "plt.title('Distribution of Titles After Consolidation');\n",
    "data['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a transformer to perfom this new feature transformation in a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T00:17:07.917449Z",
     "start_time": "2018-11-09T00:17:07.910630Z"
    }
   },
   "outputs": [],
   "source": [
    "class TitleAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features=None): # no *args or **kargs\n",
    "        self.features = features\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "    def transform(self, X):\n",
    "        df = pd.DataFrame(X, columns=self.features)\n",
    "        df['Title'] = df['Name'].apply(lambda x: re.search(' ([A-Z][a-z]+)\\.', x).group(1))\n",
    "        # Apply the necessary transformations to obtain the 5 title categories\n",
    "        # (Mr, Mrs, Miss, Master, Other) like it was done in section 5.1.2\n",
    "        #==================================================#\n",
    "        #               Your code starts here              #\n",
    "        #==================================================#\n",
    "        df['Title'] = df['Title'].replace()\n",
    "        df['Title'] = df['Title'].replace()                \n",
    "        #==================================================#\n",
    "        #               Your code ends here                #\n",
    "        #               Please don't add code below here   #\n",
    "        #==================================================#\n",
    "        df.drop('Name', axis=1, inplace=True)\n",
    "        return np.array(df.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "Now that we have explored the data, cleaned it, preprocessed it and added a new feature to it, we can start the modeling part of the project by applying Machine Learning algorithms. In this section, you will have a baseline logistic regression model and grid searches on different models. In the end, you will find out which parameters are the best for each algorithm and you will be able to compare the performance of the models with the baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T00:17:09.641330Z",
     "start_time": "2018-11-09T00:17:09.635485Z"
    }
   },
   "outputs": [],
   "source": [
    "# use full pipeline above to build full pipeline with predictor\n",
    "np.random.seed(42)\n",
    "full_pipeline_with_predictor = Pipeline([\n",
    "        (\"preparation\", full_pipeline),\n",
    "        (\"linear\", LogisticRegression(random_state=42))\n",
    "    ])\n",
    "\n",
    "data = pd.read_csv('datasets/titanic/train.csv')\n",
    "y = data['Survived']\n",
    "x = data.drop(['Survived', 'Ticket', 'Cabin'], axis = 1)\n",
    "\n",
    "# split 20% test data with random seed set to 42 for correct results\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T00:17:12.319694Z",
     "start_time": "2018-11-09T00:17:11.987069Z"
    }
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "full_pipeline_with_predictor.fit(x_train, y_train)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set up cross validation scores \n",
    "# Use ShuffleSplit() with 30 splits, 30% test_size \n",
    "# and a random seed of 0\n",
    "#==================================================#\n",
    "#               Your code starts here              #\n",
    "#==================================================#\n",
    "cv30Splits = ShuffleSplit()\n",
    "logit_scores = cross_val_score()     \n",
    "#==================================================#\n",
    "#               Your code ends here                #\n",
    "#               Please don't add code below here   #\n",
    "#==================================================#\n",
    "logit_score_train = logit_scores.mean()\n",
    "train_time = np.round(time() - start, 4)\n",
    "\n",
    "# Time and score test predictions\n",
    "start = time()\n",
    "logit_score_test  = full_pipeline_with_predictor.score(x_test, y_test)\n",
    "test_time = np.round(time() - start, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T00:17:17.543434Z",
     "start_time": "2018-11-09T00:17:17.529983Z"
    }
   },
   "outputs": [],
   "source": [
    "results.loc[0] = [\"Baseline\", pct(logit_score_train), np.round(pct(logit_score_test),3), \n",
    "                  \"---\", train_time, test_time, \"Untuned LogisticRegression\"]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have explored the data, cleaned it, preprocessed it, and added a new feature to it, we can start the modeling part of the project by applying Machine Learning algorithms. In this section we apply decision tree and random forests.\n",
    "\n",
    "Decision Tree is one of the popular and most widely used Machine Learning Algorithms because of its robustness to noise, tolerance against missing information, handling of irrelevant, redundant predictive attribute values, low computational cost, interpretability, fast run time and robust predictors. \n",
    "\n",
    "#### Cost functions used for classification and regression.\n",
    "In both cases the cost functions try to find most homogeneous branches, or branches having groups with similar responses. \n",
    "\n",
    "Regression : sum(y — prediction)²\n",
    "\n",
    "Classification : G = sum(pk * (1 — pk))\n",
    "\n",
    "A Gini score gives an idea of how good a split is by how mixed the response classes are in the groups created by the split. Here, pk is proportion of same class inputs present in a particular group.\n",
    "\n",
    "#### DecisionTreeClassifier\n",
    "\n",
    "The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “entropy” for the information gain.\n",
    "Information gain uses the entropy measure as the impurity measure and splits a node such that it gives the most amount of information gain. Whereas Gini Impurity measures the divergences between the probability distributions of the target attribute’s values and splits a node such that it gives the least amount of impurity.\n",
    "\n",
    "**Gini** :  $\\Large 1 - \\sum^m_{i=1}(P_j^2)$\n",
    "\n",
    "**Entropy** : $\\Large \\sum^m_{i=1}\\left(P_j\\cdot\\:\\log\\:\\left(P_j\\right)\\:)\\right)$\n",
    "\n",
    "#### DecisionTreeRegressor\n",
    "\n",
    "The decision of making strategic splits heavily affects a tree’s accuracy. The decision criteria is different for classification and regression trees.Decision trees regression normally use mean squared error (MSE) to decide to split a node in two or more sub-nodes. \n",
    "\n",
    "Suppose we are doing a binary tree the algorithm first will pick a value, and split the data into two subset. For each subset, it will calculate the MSE separately. The tree chooses the value with results in smallest MSE value.\n",
    "\n",
    "${MSE}=\\frac{1}{m} \\sum_{i=1}^m  (x_{i}-y_{i})^2 $\n",
    "\n",
    "#### Feature importance formula\n",
    "To calculate the importance of each feature, we will mention the decision point itself and its child nodes as well. The following formula covers the calculation of feature importance. \n",
    "\n",
    "For each decision tree, Scikit-learn calculates a nodes importance using Gini Importance, assuming only two child nodes (binary tree):\n",
    "\n",
    "$\\Large ni_j = w_jC_j - w_{left(j)}C_{left(j)} - w_{right(j)}C_{right(j)}$  \n",
    "\n",
    "**Where**\n",
    "\n",
    "ni_j= the importance of node j\n",
    "\n",
    "w_j = weighted number of samples reaching node j\n",
    "\n",
    "C_j= the impurity value of node j\n",
    "\n",
    "left(j) = child node from left split on node j\n",
    "\n",
    "right(j) = child node from right split on node j\n",
    "\n",
    "The importance for each feature on a decision tree is then calculated as:\n",
    "\n",
    "$\\Large fi_i = \\frac{\\sum_{j:node \\hspace{0.1cm} j \\hspace{0.1cm} splits \\hspace{0.1cm} on \\hspace{0.1cm} feature \\hspace{0.1cm} i}ni_j}{\\sum_{k \\hspace{0.1cm} \\epsilon \\hspace{0.1cm} all \\hspace{0.1cm} nodes }ni_k}$\n",
    "\n",
    "These can then be normalized to a value between 0 and 1 by dividing by the sum of all feature importance values:\n",
    "\n",
    "$\\Large normfi_i = \\frac{fi_i}{\\sum_{j \\hspace{0.1cm}  \\epsilon \\hspace{0.1cm} all \\hspace{0.1cm} features}fi_j}$\n",
    "\n",
    "#### Decision Trees Parameters for classification\n",
    "\n",
    "**criterion{“gini”, “entropy”}, default=”gini”** :The function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “entropy” for the information gain.\n",
    "\n",
    "**max_depth, default=None** : The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.\n",
    "\n",
    "**min_samples_leaf int or float, default=1** : The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression.\n",
    "\n",
    "#### Decision Trees Parameters for Regression\n",
    "\n",
    "**criterion{“mse”, “friedman_mse”, “mae”, “poisson”}, default=”mse”** : The function to measure the quality of a split. \n",
    "\n",
    "**max_depth, default=None** : The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.\n",
    "\n",
    "**min_samples_leaf int or float, default=1** : The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least min_samples_leaf training samples in each of the left and right branches. This may have the effect of smoothing the model, especially in regression.\n",
    "\n",
    "#### Random Forest Parameters\n",
    "\n",
    "A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. \n",
    "\n",
    "**n_estimatorsint, default=100** : The number of trees in the forest.\n",
    "\n",
    "**max_depthint, default=None** : The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples.\n",
    "\n",
    "**max_features** : The number of features to consider when looking for the best split.\n",
    "\n",
    "**min_impurity_decreasefloat, default=0.0** : Threshold for early stopping in tree growth. A node will be split if this split induces a decrease of the impurity greater than or equal to this value.\n",
    "\n",
    "**bootstrapbool, default=True** : Whether bootstrap samples are used when building trees. If False, the whole dataset is used to build each tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "boston = load_boston()\n",
    "data=pd.DataFrame(boston.data)\n",
    "data.columns = boston.feature_names\n",
    "data['PRICE']=boston.target\n",
    "X_boston,y_boston = data.iloc[:,:-1],data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_boston,X_test_boston,y_train_boston,y_test_boston = train_test_split(X_boston,y_boston,test_size=0.2,random_state=42)\n",
    "\n",
    "# Initialize and fit regressor\n",
    "\n",
    "tree = DecisionTreeRegressor(criterion='mse',max_depth=4,random_state = 42)\n",
    "tree.fit(X_train_boston, y_train_boston)\n",
    "\n",
    "y_preds_boston = tree.predict(X_test_boston)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test_boston,y_preds_boston))\n",
    "print ('RMSE=%f'% (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X_train_boston.columns\n",
    "importances = tree.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.grid()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "boston = load_boston()\n",
    "data=pd.DataFrame(boston.data)\n",
    "data.columns = boston.feature_names\n",
    "data['PRICE']=boston.target\n",
    "X_boston,y_boston = data.iloc[:,:-1],data.iloc[:,-1]\n",
    "X_train_boston,X_test_boston,y_train_boston,y_test_boston = train_test_split(X_boston,y_boston,test_size=0.2,random_state=42)\n",
    "\n",
    "RF = RandomForestRegressor(random_state = 42,n_estimators=100,criterion='mse',max_depth=6)\n",
    "\n",
    "RF.fit(X_train_boston, y_train_boston)\n",
    "\n",
    "y_preds_boston = RF.predict(X_test_boston)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test_boston,y_preds_boston))\n",
    "print ('RMSE=%f'% (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = X_train_boston.columns\n",
    "importances = RF.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.grid()\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# A Function to execute the grid search and record the results.\n",
    "def ConductGridSearch(X_train, y_train, X_test, y_test, i=0, prefix='', n_jobs=-1,verbose=1):\n",
    "    # Create a list of classifiers for our grid search experiment\n",
    "    classifiers = [\n",
    "        ('DecisionTrees', DecisionTreeClassifier(random_state=42)),\n",
    "        ('RandomForest', RandomForestClassifier(random_state=42))\n",
    "        \n",
    "    ]\n",
    "\n",
    "    # Arrange grid search parameters for each classifier\n",
    "    params_grid = {\n",
    "        'DecisionTrees' : {\n",
    "            'criterion':['gini','entropy'],\n",
    "            'max_depth':range(1,10),\n",
    "            \n",
    "            'min_samples_leaf':range(1,5)\n",
    "        },\n",
    "        \n",
    "       'RandomForest':  {\n",
    "            'max_depth': [9, 15, 22,],\n",
    "            'max_features': [1, 3, 5],\n",
    "            'min_samples_leaf': [3, 5, 10],\n",
    "            'min_impurity_decrease':[0,1e-3,1e-4,1e-6],\n",
    "            'bootstrap': [True],\n",
    "            'n_estimators':[ 100, 150, 200]}\n",
    "    }\n",
    "    \n",
    "    for (name, classifier) in classifiers:\n",
    "        i += 1\n",
    "        # Print classifier and parameters\n",
    "        print('****** START',prefix, name,'*****')\n",
    "        parameters = params_grid[name]\n",
    "        print(\"Parameters:\")\n",
    "        for p in sorted(parameters.keys()):\n",
    "            print(\"\\t\"+str(p)+\": \"+ str(parameters[p]))\n",
    "        \n",
    "        # generate the pipeline\n",
    "        full_pipeline_with_predictor = Pipeline([\n",
    "        (\"preparation\", full_pipeline),\n",
    "        (\"predictor\", classifier)\n",
    "        ])\n",
    "        \n",
    "        # Execute the grid search\n",
    "        params = {}\n",
    "        for p in parameters.keys():\n",
    "            pipe_key = 'predictor__'+str(p)\n",
    "            params[pipe_key] = parameters[p] \n",
    "        grid_search = GridSearchCV(full_pipeline_with_predictor, params, scoring='accuracy', cv=5, \n",
    "                                   n_jobs=n_jobs, verbose=verbose)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "                \n",
    "        # Best estimator score\n",
    "        best_train = pct(grid_search.best_score_)\n",
    "\n",
    "        # Best estimator fitting time\n",
    "        start = time()\n",
    "        grid_search.best_estimator_.fit(X_train, y_train)\n",
    "        train_time = round(time() - start, 4)\n",
    "        \n",
    "#         plt.barh(['Age', 'Parch', 'SibSp','Fare','x0_C' ,'x0_Q' ,'x0_S' ,'x1_female', 'x1_male' ,'x2_1' ,'x2_2', 'x2_3'], grid_search.best_estimator_.named_steps[\"predictor\"].feature_importances_)\n",
    "#         plt.show()\n",
    "        features = ['Age', 'Parch', 'SibSp','Fare','x0_C' ,'x0_Q' ,'x0_S' ,'x1_female', 'x1_male' ,'x2_1' ,'x2_2', 'x2_3']\n",
    "        importances = grid_search.best_estimator_.named_steps[\"predictor\"].feature_importances_\n",
    "        indices = np.argsort(importances)\n",
    "\n",
    "        plt.title('Feature Importances')\n",
    "        plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "        plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "        plt.xlabel('Relative Importance')\n",
    "        plt.grid()\n",
    "        plt.show();\n",
    "        # Best estimator prediction time\n",
    "        start = time()\n",
    "        best_test_accuracy = pct(grid_search.best_estimator_.score(X_test, y_test))\n",
    "        test_time = round(time() - start, 4)\n",
    "\n",
    "        # Generate 30 training accuracy scores with the best estimator and 30-split CV\n",
    "        # To calculate the best_train_accuracy use the pct() and mean() methods\n",
    "        #==================================================#\n",
    "        #               Your code starts here              #\n",
    "        #==================================================#\n",
    "        best_train_scores = cross_val_score(..., cv=cv30Splits)\n",
    "        best_train_accuracy = pct()\n",
    "        #==================================================#\n",
    "        #               Your code ends here                #\n",
    "        #               Please don't add code below here   #\n",
    "        #==================================================#    \n",
    "       \n",
    "        # Conduct t-test with baseline logit (control) and best estimator (experiment)\n",
    "        (t_stat, p_value) = stats.ttest_rel(logit_scores, best_train_scores)\n",
    "        \n",
    "        # Collect the best parameters found by the grid search\n",
    "        print(\"Best Parameters:\")\n",
    "        best_parameters = grid_search.best_estimator_.get_params()\n",
    "        param_dump = []\n",
    "        for param_name in sorted(params.keys()):\n",
    "            param_dump.append((param_name, best_parameters[param_name]))\n",
    "            print(\"\\t\"+str(param_name)+\": \" + str(best_parameters[param_name]))\n",
    "        print(\"****** FINISH\",prefix,name,\" *****\")\n",
    "        print(\"\")\n",
    "        \n",
    "        # Record the results\n",
    "        results.loc[i] = [prefix+name, best_train_accuracy, best_test_accuracy, round(p_value,5), train_time, test_time, json.dumps(param_dump)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# This might take a while\n",
    "if __name__ == \"__main__\":\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected\n",
    "    # block\n",
    "\n",
    "    # find the best parameters for both the feature extraction and the\n",
    "    # classifier\n",
    "    # n_jobs=-1 means that the computation will be dispatched on all the CPUs of the computer.\n",
    "    #\n",
    "    # By default, the GridSearchCV uses a 3-fold cross-validation. However, if it \n",
    "    #            detects that a classifier is passed, rather than a regressor, it uses a stratified 3-fold.\n",
    "    \n",
    "    data = pd.read_csv('datasets/titanic/train.csv')\n",
    "    y = data['Survived']\n",
    "    x = data.drop(['Survived', 'Ticket', 'Cabin'], axis = 1)\n",
    "\n",
    "    # split 20% test data with random seed set to 42 for correct results\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.2, shuffle=True, random_state=42)\n",
    "    ConductGridSearch(x_train, y_train, x_test, y_test, 0, \"Best Model:\",  n_jobs=-1,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conduct Grid Search using a variety of Classification Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we're going to try to answer the following questions\n",
    "Note: These questions should be answered in Canvas once you have completed this section.\n",
    "### Best train accuracy\n",
    "    Please submit the code snippet you added to calculate the best train accuracy in the section below of the notebook\n",
    "### Best parameters for Logistic Regression \n",
    "    Based on the results obtained after conducting Grid Search in this section , choose the best parameters for Logistic Regression\n",
    "### Best parameters for k-nearest neighbors\n",
    "    Based on the results obtained after conducting Grid Search in this section, what is  the best parameter for n_neighbors for k-nearest neighbors?\n",
    "### SVM Test Accuracy\n",
    "Please enter the calculated value for test Accuracy of Support vector model in the section below of the notebook. \n",
    "(Report your number to 1 decimal point of precision. For example: 2.5)\n",
    "### Statistical significance\n",
    "    Which one of the models listed below is the most statistically significant based on the results of this section? \n",
    "    * Naive Bayes\n",
    "    * Stochastic GD\n",
    "    * RandomForest\n",
    "    * Logistic Regression\n",
    "### Choosing the best model\n",
    "    Given the results that you obtained for the different models in this section, based on what information would you choose the best model to deploy? \n",
    "    * Cross fold Train Accuracy\n",
    "    * Test Accuracy\n",
    "    * p-value\n",
    "    * Train Time\n",
    "    * Test Time\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T00:26:48.823849Z",
     "start_time": "2018-11-09T00:26:48.804151Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# A Function to execute the grid search and record the results.\n",
    "def ConductGridSearch(X_train, y_train, X_test, y_test, i=0, prefix='', n_jobs=-1,verbose=1):\n",
    "    # Create a list of classifiers for our grid search experiment\n",
    "    classifiers = [\n",
    "        ('Logistic Regression', LogisticRegression(random_state=42)),\n",
    "        ('K-Nearest Neighbors', KNeighborsClassifier()),\n",
    "        ('Naive Bayes', GaussianNB()),\n",
    "        ('Support Vector', SVC(random_state=42)),\n",
    "        ('Stochastic GD', SGDClassifier(random_state=42)),\n",
    "        ('RandomForest', RandomForestClassifier(random_state=42)),\n",
    "    ]\n",
    "\n",
    "    # Arrange grid search parameters for each classifier\n",
    "    params_grid = {\n",
    "        'Logistic Regression': {\n",
    "            'penalty': ('l1', 'l2'),\n",
    "            'tol': (0.0001, 0.00001, 0.0000001), \n",
    "            'C': (10, 1, 0.1, 0.01),\n",
    "        },\n",
    "        'K-Nearest Neighbors': {\n",
    "            'n_neighbors': (3, 5, 7, 8, 11),\n",
    "            'p': (1,2),\n",
    "        },\n",
    "        'Naive Bayes': {},\n",
    "        'Support Vector' : {\n",
    "            'kernel': ('rbf', 'poly'),     \n",
    "            'degree': (1, 2, 3, 4, 5),\n",
    "            'C': (10, 1, 0.1, 0.01),\n",
    "        },\n",
    "        'Stochastic GD': {\n",
    "            'loss': ('hinge', 'perceptron', 'log'),\n",
    "            'penalty': ('l1', 'l2', 'elasticnet'),\n",
    "            'tol': (0.0001, 0.00001, 0.0000001), \n",
    "            'alpha': (0.1, 0.01, 0.001, 0.0001), \n",
    "        },\n",
    "        'RandomForest':  {\n",
    "            'max_depth': [9, 15, 22, 26, 30],\n",
    "            'max_features': [1, 3, 5],\n",
    "            'min_samples_split': [5, 10, 15],\n",
    "            'min_samples_leaf': [3, 5, 10],\n",
    "            'bootstrap': [False],\n",
    "            'n_estimators':[20, 80, 150, 200, 300]},\n",
    "    }\n",
    "    \n",
    "    for (name, classifier) in classifiers:\n",
    "        i += 1\n",
    "        # Print classifier and parameters\n",
    "        print('****** START',prefix, name,'*****')\n",
    "        parameters = params_grid[name]\n",
    "        print(\"Parameters:\")\n",
    "        for p in sorted(parameters.keys()):\n",
    "            print(\"\\t\"+str(p)+\": \"+ str(parameters[p]))\n",
    "        \n",
    "        # generate the pipeline\n",
    "        full_pipeline_with_predictor = Pipeline([\n",
    "        (\"preparation\", full_pipeline),\n",
    "        (\"predictor\", classifier)\n",
    "        ])\n",
    "        \n",
    "        # Execute the grid search\n",
    "        params = {}\n",
    "        for p in parameters.keys():\n",
    "            pipe_key = 'predictor__'+str(p)\n",
    "            params[pipe_key] = parameters[p] \n",
    "        grid_search = GridSearchCV(full_pipeline_with_predictor, params, scoring='accuracy', cv=5, \n",
    "                                   n_jobs=n_jobs, verbose=verbose)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "                \n",
    "        # Best estimator score\n",
    "        best_train = pct(grid_search.best_score_)\n",
    "\n",
    "        # Best estimator fitting time\n",
    "        start = time()\n",
    "        grid_search.best_estimator_.fit(X_train, y_train)\n",
    "        train_time = round(time() - start, 4)\n",
    "\n",
    "        # Best estimator prediction time\n",
    "        start = time()\n",
    "        best_test_accuracy = pct(grid_search.best_estimator_.score(X_test, y_test))\n",
    "        test_time = round(time() - start, 4)\n",
    "\n",
    "        # Generate 30 training accuracy scores with the best estimator and 30-split CV\n",
    "        # To calculate the best_train_accuracy use the pct() and mean() methods\n",
    "        #==================================================#\n",
    "        #               Your code starts here              #\n",
    "        #==================================================#\n",
    "        best_train_scores = cross_val_score( ...., cv=cv30Splits)\n",
    "        best_train_accuracy = pct()  \n",
    "        #=================================================#\n",
    "        #               Your code ends here                #\n",
    "        #               Please don't add code below here   #\n",
    "        #==================================================#    \n",
    "       \n",
    "        # Conduct t-test with baseline logit (control) and best estimator (experiment)\n",
    "        (t_stat, p_value) = stats.ttest_rel(logit_scores, best_train_scores)\n",
    "        \n",
    "        # Collect the best parameters found by the grid search\n",
    "        print(\"Best Parameters:\")\n",
    "        best_parameters = grid_search.best_estimator_.get_params()\n",
    "        param_dump = []\n",
    "        for param_name in sorted(params.keys()):\n",
    "            param_dump.append((param_name, best_parameters[param_name]))\n",
    "            print(\"\\t\"+str(param_name)+\": \" + str(best_parameters[param_name]))\n",
    "        print(\"****** FINISH\",prefix,name,\" *****\")\n",
    "        print(\"\")\n",
    "        \n",
    "        # Record the results\n",
    "        results.loc[i] = [prefix+name, best_train_accuracy, best_test_accuracy, round(p_value,5), train_time, test_time, json.dumps(param_dump)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T00:35:36.766006Z",
     "start_time": "2018-11-09T00:26:52.737779Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# This might take a while\n",
    "if __name__ == \"__main__\":\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected\n",
    "    # block\n",
    "\n",
    "    # find the best parameters for both the feature extraction and the\n",
    "    # classifier\n",
    "    # n_jobs=-1 means that the computation will be dispatched on all the CPUs of the computer.\n",
    "    #\n",
    "    # By default, the GridSearchCV uses a 3-fold cross-validation. However, if it \n",
    "    #            detects that a classifier is passed, rather than a regressor, it uses a stratified 3-fold.\n",
    "    data = pd.read_csv('datasets/titanic/train.csv')\n",
    "    y = data['Survived']\n",
    "    x = data.drop(['Survived', 'Ticket', 'Cabin'], axis = 1)\n",
    "\n",
    "    # split 20% test data with random seed set to 42 for correct results\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.2, shuffle=True, random_state=42)\n",
    "    ConductGridSearch(x_train, y_train, x_test, y_test, 0, \"Best Model:\",  n_jobs=-1,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-09T00:35:36.843340Z",
     "start_time": "2018-11-09T00:35:36.832770Z"
    }
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The Support Vector Classifier with parameters [C=10, degree=2, kernel=poly] had the best overall performance followed by the Random Forest classifier. The p-values of 0.00057 and 0.0001, respectively, indicate that both results are signficantly different from the baseline Logistic Regression model. \n",
    "* There tuned Logistic Regression was not statistically different than the baseline (untuned) model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPTIONAL: TMDB Box Office Prediction on Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " For this part of the homework \n",
    "You will need to look at the  [TMDB Box Office Prediction Competition on Kaggle](https://www.kaggle.com/c/tmdb-box-office-prediction)\n",
    "Through the lectures and lab we learned how to predict house prices in California. In this homework, we adopted  the end to end pipeline to tackle the Titanic Survival problem. Now, we want you to adopt the machine learning pipeline to tackle the TMDB Box Office Prediction\n",
    "\n",
    "In this dataset, you are provided with 7,398  movies (3,000 for training and 4,398 for testing) and a variety of metadata obtained from The Movie Database (TMDB). Movies are labeled with id. Data points include cast, crew, plot keywords, budget, posters, release dates, languages, production companies, and countries.\n",
    "\n",
    "Feel free to use the [Kaggle API](https://github.com/Kaggle/kaggle-api) for downloading the dataset or submitting to the competition. It is not mandatory to use the package but it would be interesting to explore.\n",
    "   You will need to: \n",
    "* __Important:__ Make sure your results are reproducible \n",
    "* __Important:__ Use the training data set provided by the competition to create a training set(70%), validation set (15%) and a test set (15%)\n",
    "* __EDA.__ Identify the types of data available, evaluate basic statistical information about the data and determine whether you have any missing or misformated data.\n",
    "\n",
    "* __Feature Engineering.__  Develop at least one new feature based on the existing features of the dataset\n",
    "* __Pre-processing.__  All work must be performed using pipelines.  You can adapt code from above or develop your own.\n",
    "* __Modeling.__Evaluate at least two appropriate algorithms (estimators) for generating predictions.\n",
    "    * Use grid search to tune hyperparameters.\n",
    "    * Use crossfold evaluation (cv=5).\n",
    "* __Evaluation.__ Select appropriate metrics for the problem to evaluate your models.\n",
    "* __Reporting.__ Record all experiments in a table of results (pandas dataframe) including at least the following information:  \n",
    "    * description of the model (algorithim, notable processing steps) \n",
    "    * key hyperparameters\n",
    "    * results (using one or more appropriate metrics)\n",
    "    * run time for each experiment (train and test results)\n",
    "    * hardware used\n",
    "* __Analysis__. Perform a significance test on your best models and discuss results (see Module 09.5 in Canvas for a video lecture on significance testing).\n",
    "* __Submit your best model to Kaggle__ Provide a screenshot of the kaggle submission\n",
    "* __Comment your code and provide explanations of how you're proceeding in each part__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import & notebook preperation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('datasets/TMDB/train.csv')\n",
    "y = data ['revenue']\n",
    "x = data .drop(['revenue'], axis = 1)\n",
    "test_data = pd.read_csv('datasets/TMDB/test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* __Important:__ Remember that x and y should be split into a training set (70% of the original dataset), a validation set (15% of the original dataset) and a test set (15% of the original dataset. \n",
    "* test_data will be only used for the kaggle submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation, reporting and analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
