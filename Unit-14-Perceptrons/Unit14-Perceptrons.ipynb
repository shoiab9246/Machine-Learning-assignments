{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__For HW14, you will be expected to answer questions about your work in this notebook via Canvas (Modules->Module 14->HW14 Notebook and submission form). You may wish to reference this quiz while working through the assignment.__\n",
    "## Submission instructionsÂ¶\n",
    "Before completing this homework,\n",
    "1. please review this homework's submission form on Canvas available under the \"Modules\" menu option and briefly review this notebook end to end.\n",
    "2. To get you started we provide a template solution with missing code and prompts. Please complete the missing code, run the experiments and log your results.\n",
    "3. When you're sufficiently happy with your results, please begin the submission process on Canvas. Use the submission form for this homework available under \"Modules\" menu option. Please note that the submission form is available at the same place where you downloaded the homework from.\n",
    "4. You may wish to reference the submission form (Modules->Module 13->HW13 Notebook and submission form) while working through the tasks.\n",
    "\n",
    "Please complete all core assignment tasks (marked \"TASK\"). For bonus points, please complete the optional stretech assignment tasks (marked \"OPTIONAL\").\n",
    "\n",
    "The goals of this HW include the following:\n",
    "* Understanding the operation of a multiclass perceptron classifier.\n",
    "* Building a multiclass perceptron classifier.\n",
    "    * Applying regularization\n",
    "    * Evaluating performance metrics unique to a multiclass problem.\n",
    "* Tuning a multiclass perceptron for text classification.\n",
    "  \n",
    "You will submit the results of your work in this notebook using the **HW14 Submission Form** assignment on Canvas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-17T21:05:11.015743Z",
     "start_time": "2018-11-17T21:05:11.012949Z"
    }
   },
   "source": [
    "## Prepare the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T22:29:33.648649Z",
     "start_time": "2018-11-21T22:29:30.646214Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.datasets import make_classification\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import reuters\n",
    "nltk.download('stopwords')\n",
    "nltk.download('reuters')\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines \n",
    "In this section of the notebook, we are doing a background review of your understanding of SVM. The first part is plotting different SVM kernels and see how that changes the classification. \n",
    "The second part aims to show the effects of margins on SVM classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot different Kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, svm\n",
    "import matplotlib.patches as mpatches\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X = X[y != 0, :2]\n",
    "y = y[y != 0]\n",
    "\n",
    "n_sample = len(X)\n",
    "colors = ['green','blue']\n",
    "groups=[\"Class 1 points\", \"Class 2 points\"]\n",
    "np.random.seed(0)\n",
    "order = np.random.permutation(n_sample)\n",
    "X = X[order]\n",
    "y = y[order].astype(np.float)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=42)\n",
    "\n",
    "# fit the model\n",
    "for fig_num, kernel in enumerate(('linear', 'rbf', 'poly')):\n",
    "    # create an svm model for each of the kernels with gamma=10\n",
    "    # fit the train data and calculate accuracy for train & test data\n",
    "    #==================================================#\n",
    "    #               Your code starts here              #\n",
    "    #==================================================#\n",
    "    clf = svm.SVC()\n",
    "    clf.fit()\n",
    "    train_acc= \n",
    "    test_acc= \n",
    "    #==================================================#\n",
    "    #               Your code ends here                #\n",
    "    #               Please don't add code below here   #\n",
    "    #==================================================#\n",
    "    print (kernel , \" kernel => train accuracy:\", np.round(train_acc,3), \"test accuracy: \", np.round(test_acc,3))\n",
    "    print( \"number of support vectors\",np.sum(clf.n_support_))\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.figure(fig_num)\n",
    "    plt.clf()\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, zorder=10, s=20,cmap=matplotlib.colors.ListedColormap(colors))\n",
    "    plt.axis('tight')\n",
    "    x_min = X[:, 0].min()\n",
    "    x_max = X[:, 0].max()\n",
    "    y_min = X[:, 1].min()\n",
    "    y_max = X[:, 1].max()\n",
    "\n",
    "    XX, YY = np.mgrid[x_min:x_max:200j, y_min:y_max:200j]\n",
    "    Z = clf.decision_function(np.c_[XX.ravel(), YY.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(XX.shape)\n",
    "    #plt.pcolormesh(XX, YY, Z > 0, cmap=plt.cm.Paired)\n",
    "    plt.contour(XX, YY, Z, colors=['k', 'k', 'k'],\n",
    "                linestyles=['--', '-', '--'], levels=[-.5, 0, .5])\n",
    "    plt.scatter(clf.support_vectors_[:,0],clf.support_vectors_[:,1], c='r', s=30, label= \"support vectors\")\n",
    "    red_patch = mpatches.Patch(color='red', label='Support Vectors')\n",
    "    blue_patch = mpatches.Patch(color='blue', label='Class 1 points')\n",
    "    green_patch = mpatches.Patch(color='green', label='Class 2 points')\n",
    "    plt.legend(handles=[red_patch, blue_patch,green_patch])\n",
    "    plt.title(kernel)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soft margin vs. harder margins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X = X[y != 2, :2]\n",
    "y = y[y != 2]\n",
    "\n",
    "n_sample = len(X)\n",
    "\n",
    "np.random.seed(0)\n",
    "order = np.random.permutation(n_sample)\n",
    "X = X[order]\n",
    "y = y[order].astype(np.float)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "svm_clf1 = LinearSVC(C=1, loss=\"hinge\", random_state=42)    # Soft SVM\n",
    "svm_clf2 = LinearSVC(C=100, loss=\"hinge\", random_state=42)  #Harder SVM\n",
    "# build the two pipelines for the for the soft svm and the harder svm\n",
    "# the first step is sclaing the data for both pipelines\n",
    "#==================================================#\n",
    "#               Your code starts here              #\n",
    "#==================================================#\n",
    "scaled_svm_clf1 = Pipeline([\n",
    "        (\"scaler\", ),\n",
    "        (\"linear_svc1\", ),\n",
    "])\n",
    "scaled_svm_clf2 = Pipeline([\n",
    "        (\"scaler\", scaler),\n",
    "       (\"linear_svc2\", ),\n",
    "]) \n",
    "#==================================================#\n",
    "#               Your code ends here                #\n",
    "#               Please don't add code below here   #\n",
    "#==================================================#\n",
    "scaled_svm_clf1.fit(X_train, y_train)\n",
    "scaled_svm_clf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to unscaled parameters\n",
    "b1 = svm_clf1.decision_function([-scaler.mean_ / scaler.scale_])\n",
    "b2 = svm_clf2.decision_function([-scaler.mean_ / scaler.scale_])\n",
    "w1 = svm_clf1.coef_[0] / scaler.scale_\n",
    "w2 = svm_clf2.coef_[0] / scaler.scale_\n",
    "svm_clf1.intercept_ = np.array([b1])\n",
    "svm_clf2.intercept_ = np.array([b2])\n",
    "svm_clf1.coef_ = np.array([w1])\n",
    "svm_clf2.coef_ = np.array([w2])\n",
    "\n",
    "# Find support vectors (LinearSVC does not do this automatically)\n",
    "t = y * 2 - 1\n",
    "support_vectors_idx1 = (t * (X.dot(w1) + b1) < 1).ravel()\n",
    "support_vectors_idx2 = (t * (X.dot(w2) + b2) < 1).ravel()\n",
    "svm_clf1.support_vectors_ = X[support_vectors_idx1]\n",
    "svm_clf2.support_vectors_ = X[support_vectors_idx2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_svc_decision_boundary(svm_clf, xmin, xmax):\n",
    "    w = svm_clf.coef_[0]\n",
    "    b = svm_clf.intercept_[0]\n",
    "\n",
    "    # At the decision boundary, w0*x0 + w1*x1 + b = 0\n",
    "    # => x1 = -w0/w1 * x0 - b/w1\n",
    "    x0 = np.linspace(xmin, xmax, 200)\n",
    "    decision_boundary = -w[0]/w[1] * x0 - b/w[1]\n",
    "    # Complete the code below to calculate the margin\n",
    "    # and gutter_up and gutter_down for the decision boundary\n",
    "    #==================================================#\n",
    "    #               Your code starts here              #\n",
    "    #==================================================#\n",
    "    margin = \n",
    "    gutter_up = \n",
    "    gutter_down = \n",
    "    #==================================================#\n",
    "    #               Your code ends here                #\n",
    "    #               Please don't add code below here   #\n",
    "    #==================================================#\n",
    "    \n",
    "    \n",
    "    # NOTE: we have two support vectors\n",
    "    svs = svm_clf.support_vectors_\n",
    "    plt.scatter(svs[:, 0], svs[:, 1], s=180, facecolors='#FFAAAA')\n",
    "    plt.plot(x0, decision_boundary, \"k-\", linewidth=2)\n",
    "    plt.plot(x0, gutter_up, \"k--\", linewidth=2)\n",
    "    plt.plot(x0, gutter_down, \"k--\", linewidth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc1= scaled_svm_clf1.score(X_train,y_train)\n",
    "test_acc1= scaled_svm_clf1.score (X_test,y_test)\n",
    "train_acc2= scaled_svm_clf2.score(X_train,y_train)\n",
    "test_acc2= scaled_svm_clf2.score (X_test,y_test)\n",
    "print (\" soft margins C=1 => train accuracy:\", train_acc1, \"test accuracy: \", test_acc1)\n",
    "print (\" harder margins C=100 => train accuracy:\", train_acc2, \"test accuracy: \", test_acc2)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(121)\n",
    "plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"g^\", label=\"Iris-Virginica\")\n",
    "plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"bo\", label=\"Iris-Versicolor\")\n",
    "plot_svc_decision_boundary(svm_clf1, 2, 8)\n",
    "plt.xlabel(\"Petal length\", fontsize=14)\n",
    "plt.ylabel(\"Petal width\", fontsize=14)\n",
    "plt.legend(loc=\"upper left\", fontsize=14)\n",
    "plt.title(\"$C = {}$\".format(svm_clf1.C), fontsize=16)\n",
    "plt.axis([4,7, 1, 5])\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"g^\")\n",
    "plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"bo\")\n",
    "plot_svc_decision_boundary(svm_clf2, 2, 8)\n",
    "plt.xlabel(\"Petal length\", fontsize=14)\n",
    "plt.title(\"$C = {}$\".format(svm_clf2.C), fontsize=16)\n",
    "plt.axis([4, 7, 1.5, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK: Multiclass Preceptron : variable importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the hyperplane coefficients barchart  with the pairwise visualization and complete the analysis provided below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data and build a perceptron classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T01:46:34.927804Z",
     "start_time": "2018-11-18T01:46:34.908707Z"
    }
   },
   "outputs": [],
   "source": [
    "irisDataset = load_iris() \n",
    "\n",
    "X = irisDataset.data\n",
    "y = irisDataset.target\n",
    "\n",
    "#create a heldout dataset for final testing only\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.15, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.15, random_state=42)\n",
    "df = pd.DataFrame(X, columns=irisDataset.feature_names)\n",
    "df['IrisClass'] = y\n",
    "\n",
    "perceptron_pipeline = Pipeline([\n",
    "        #('imputer', Imputer(strategy=\"median\")), #Use the \"median\" to impute missing vlaues\n",
    "        ('std_scaler', StandardScaler()),\n",
    "        ('perceptron', Perceptron(random_state=42))\n",
    "    ])\n",
    "# Fit the train data to the pipeline\n",
    "# Predict for X-test\n",
    "#==================================================#\n",
    "#               Your code starts here              #\n",
    "#==================================================#\n",
    "perceptron_pipeline.fit()\n",
    "preds = \n",
    "#==================================================#\n",
    "#               Your code ends here                #\n",
    "#               Please don't add code below here   #\n",
    "#==================================================#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate visualizations (pairwise scatterplot and bar chart of the model coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T01:46:38.806120Z",
     "start_time": "2018-11-18T01:46:34.929719Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(sns.load_dataset(\"iris\"), hue=\"species\", height=4);\n",
    "\n",
    "model = perceptron_pipeline.named_steps['perceptron']\n",
    "print(np.round(model.coef_,3))\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.bar(np.arange(model.coef_.shape[1]) - 0.2, model.coef_[0], color=\"red\", width=0.2, label=\"setosa\")\n",
    "plt.bar(np.arange(model.coef_.shape[1]) - 0.0, model.coef_[1], color=\"green\", width=0.2, label=\"versicolour\")\n",
    "plt.bar(np.arange(model.coef_.shape[1]) + 0.2, model.coef_[2], color=\"blue\", width=0.2, label=\"virginica\")\n",
    "plt.xticks(np.arange(model.coef_.shape[1]), df.columns[:4], rotation=0)\n",
    "plt.xlim([-1, model.coef_.shape[1]])\n",
    "plt.title(\"Multiclass Perceptron Model coefficients\")\n",
    "plt.legend(loc=\"lower right\");\n",
    "plt.grid()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in the blanks to complete the analysis\n",
    "\n",
    "Use the results of the hyperplane cooefficient's barchart with the pairwise feature distributions to understand how the different features can be used to classify the different iris classes\n",
    "\n",
    "**Fill in the appropriate text:**\n",
    "\n",
    "Compare the hyperplane cooefficients barplot above with the pairwise feature distributions plotted previously.\n",
    "\n",
    "Looking at the barplot, one can see that ___ has the least influence on defining a separating hyperplane for the versicolour class.  Looking at the the pairwise plot, this feature does not distinguish versicolour in combination with any other feature.\n",
    "\n",
    "Looking at the second column on the pairwise plot, setosa and versicolor classes are both impossible to distinguish based on ___ ; we can observe that 99% of the vertical lines that can be drawn, contain more than one class and hence wont be able to separate classes based on this feature.\n",
    "\n",
    "Both petal width and petal length are excellent features to consider since either one can separate 100% of ___ .  In combination, they are able to separate close to 100% of the remaining classes too. ___  is the most influential factor in determining ____ class. This is also clearly visible in the pairwise plot, as 99% of the vertical lines clearly indicate exactly one class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK: Multiclass  perceptron with regularization\n",
    "\n",
    "\n",
    "Using the SKLearn class `SGDClassifier` within the pipeline provided below, learn multiclass perceptron using gridsearch to evaluate:\n",
    "* L1, L2 and elasticnet regularization\n",
    "* alpha values $\\in [10, 1, 0.1, 0.01, 0.001)$\n",
    "\n",
    "Report your the accuracy score on your test data and the hyperparameters for your best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T01:46:41.557326Z",
     "start_time": "2018-11-18T01:46:38.809117Z"
    }
   },
   "outputs": [],
   "source": [
    "# The number of informative features. Each class is composed of a number\n",
    "# of gaussian clusters each located around the vertices of a hypercube\n",
    "# in a subspace of dimension ``n_informative``. For each cluster,\n",
    "# informative features are drawn independently from  N(0, 1) and then\n",
    "# randomly linearly combined within each cluster in order to add\n",
    "# covariance. The clusters are then placed on the vertices of the\n",
    "# hypercube.\n",
    "\n",
    "# generate classification dataset\n",
    "x, y = make_classification(1000, n_classes=3, n_informative=6, random_state=42)\n",
    "\n",
    "# generate splits for crossfold validation\n",
    "cv = KFold(3, random_state=42, shuffle=True)\n",
    "cv_idx = cv.split(x)\n",
    "\n",
    "\n",
    "# Create a pipeline, where the first step is scaling the features using StandardScaler()\n",
    "# and the second step is SGDClassifier() with loss='perceptron' and random_state=42\n",
    "#==================================================#\n",
    "#               Your code starts here              #\n",
    "#==================================================#\n",
    "pipeline = Pipeline([\n",
    "      ('std_scaler', ),\n",
    "      ('perceptron', )\n",
    "])\n",
    "#==================================================#\n",
    "#               Your code ends here                #\n",
    "#               Please don't add code below here   #\n",
    "#==================================================#\n",
    "\n",
    "\n",
    "parameters = { \n",
    "    'perceptron__alpha': (10, 1, 0.1, 0.01, 0.001),\n",
    "    'perceptron__penalty': ('l1', 'l2', 'elasticnet'),\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=cv_idx, n_jobs=-1, verbose=1, )\n",
    "grid_search.fit(x,y)\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "preds = grid_search.predict(x)\n",
    "accuracy = accuracy_score(preds, y)\n",
    "\n",
    "results = pd.DataFrame(columns=[\"Model\", \"Test Accuracy\"])\n",
    "results.loc[len(results)] = [\"Perceptron\", np.round(accuracy, 3)]\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate F1 score with micro and macro averaging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### Equation  $F_1$ score\n",
    "\n",
    "$\n",
    "F_1 = \\cfrac{2}{\\cfrac{1}{\\text{precision}} + \\cfrac{1}{\\text{recall}}} = 2 \\times \\cfrac{\\text{precision}\\, \\times \\, \\text{recall}}{\\text{precision}\\, + \\, \\text{recall}} = \\cfrac{TP}{TP + \\cfrac{FN + FP}{2}}\n",
    "$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "So for our Reuters multiclass classification problem the labels are not binary, but are one-hot encoded. Fortunately, there are  options that work with this type of labeled  data for Precision:\n",
    "\n",
    "* precision_score(y_test, y_pred, average=None) will return the precision scores for each class, while\n",
    "* precision_score(y_test, y_pred, average='micro') will return the total ratio of tp/(tp + fp)\n",
    "* precision_score(y_test, y_pred, average='macro') will return macro average (class average = sum(precision)/numOfClasses). This is option is much preferred which dealing with imbalanced data.\n",
    "\n",
    "The same is true for other performance measures such as F1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run this code to generate targets and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T01:46:41.596137Z",
     "start_time": "2018-11-18T01:46:41.561849Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "_, y1 = make_classification(n_samples=20, n_features=100, n_informative=30, n_classes=5, random_state=12)\n",
    "y2 = shuffle(y1, random_state=1)\n",
    "y3 = shuffle(y1, random_state=2)\n",
    "y4 = shuffle(y1, random_state=3)\n",
    "\n",
    "\n",
    "y_text = np.vstack((y1, y2, y3, y4)).T\n",
    "\n",
    "# One hot encode the target class variables\n",
    "mlb = MultiLabelBinarizer(classes=(0, 1, 2, 3, 4))\n",
    "y = mlb.fit_transform(y_text)\n",
    "\n",
    "# Use make_classification to create a cluster of 20 sample points\n",
    "# with a 100 features, 30 informative features, 5 classes\n",
    "# and random state =42\n",
    "#==================================================#\n",
    "#               Your code starts here              #\n",
    "#==================================================#\n",
    "_, y1 = make_classification()\n",
    "#==================================================#\n",
    "#               Your code ends here                #\n",
    "#               Please don't add code below here   #\n",
    "#==================================================#\n",
    "\n",
    "\n",
    "y2 = shuffle(y1, random_state=1)\n",
    "y3 = shuffle(y1, random_state=2)\n",
    "y4 = shuffle(y1, random_state=3)\n",
    "y5 = shuffle(y1, random_state=4)\n",
    "\n",
    "#NOTE: Y target vector for 3 classes\n",
    "# note that each example can have one or MORE class labels\n",
    "y_preds_text = np.vstack((y1, y2, y3, y4, y5)).T     \n",
    "# One hot encode the target class variables\n",
    "mlb = MultiLabelBinarizer(classes=(0, 1, 2, 3, 4))\n",
    "y_preds = mlb.fit_transform(y_preds_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These are the 20 multilabel targets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T01:46:41.602684Z",
     "start_time": "2018-11-18T01:46:41.598233Z"
    }
   },
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These are the 20 predictions generated by our \"model\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T01:46:41.608774Z",
     "start_time": "2018-11-18T01:46:41.605105Z"
    }
   },
   "outputs": [],
   "source": [
    "print(y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK: Using the one-hot encorded targets and predictions data above (for 20 multi-label samples) calculate the F1 score using a micro and macro approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T01:46:41.620321Z",
     "start_time": "2018-11-18T01:46:41.611177Z"
    }
   },
   "outputs": [],
   "source": [
    "# Complete the following code to calculate the\n",
    "# F1 score with the micro and macro approach\n",
    "#==================================================#\n",
    "#               Your code starts here              #\n",
    "#==================================================#\n",
    "print(\"F1 Micro:\",round(f1_score(....),3))\n",
    "print(\"F1 Macro:\",round(f1_score(....),3))\n",
    "#==================================================#\n",
    "#               Your code ends here                #\n",
    "#               Please don't add code below here   #\n",
    "#==================================================#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Optional Task] Reuters classification with different numbers of classes k\n",
    "\n",
    "Using the code provided below, generate a series of experiments based on the Reuters dataset:\n",
    "\n",
    "At a minimum:\n",
    "* Compare the perceptron algorithm to logistic regression (\"log\" loss). \n",
    "* Experiment with unigrams and bigrams.\n",
    "* Experiment with at least two more hyperparameters.\n",
    "\n",
    "Keep a log of your results for each experiment in a table of results (pandas dataframe).  Your table of results should be a meaningful record or your work on this task, not a dump of grid search output for one experiment.  Please include:\n",
    "* Description of the model (e.g., Baseline Logistic Regression k=30, Perceptron k=50, etc.).\n",
    "* Identify key hyperparameters.\n",
    "* Precision, recall and F1 scores calculated using micro and macro approach.\n",
    "* Time to complete the experiment.\n",
    "* Hardware used.\n",
    "\n",
    "Think about how (and why) these changes affect your results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T22:29:44.767375Z",
     "start_time": "2018-11-21T22:29:42.463957Z"
    }
   },
   "outputs": [],
   "source": [
    "documents = reuters.fileids()\n",
    "test = [d for d in documents if d.startswith('test/')]\n",
    "train = [d for d in documents if d.startswith('training/')]\n",
    "\n",
    "cachedStopWords = nltk.download(\"stopwords\") #stopwords.words(\"english\")\n",
    "cachedStopWords = nltk.corpus.stopwords.words('english')\n",
    "np.random.seed(42)\n",
    "def loadReutersTrainTest():\n",
    "    documents = reuters.fileids()\n",
    "    train_docs_id = list(filter(lambda doc: doc.startswith(\"train\"), documents))\n",
    "    test_docs_id = list(filter(lambda doc: doc.startswith(\"test\"), documents))\n",
    "    #Input text\n",
    "    train_docs = [reuters.raw(doc_id) for doc_id in train_docs_id]\n",
    "    test_docs = [reuters.raw(doc_id) for doc_id in test_docs_id]\n",
    "    #Categories \n",
    "    # Complete the following code to get the categories\n",
    "    # of the train and the test set\n",
    "    #==================================================#\n",
    "    #               Your code starts here              #\n",
    "    #==================================================#\n",
    "    train_target_names = [reuters.categories(...) for ... in ...]\n",
    "    test_target_names = [reuters.categories(...) for ... in ...]\n",
    "    #==================================================#\n",
    "    #               Your code ends here                #\n",
    "    #               Please don't add code below here   #\n",
    "    #==================================================#\n",
    "    return(train_docs, test_docs, train_target_names, test_target_names)\n",
    "\n",
    "train_docs, test_docs, train_target_names, test_target_names = loadReutersTrainTest()\n",
    "\n",
    "print(\"Number of train docs is \", len(train_docs))\n",
    "print(\"Number of test docs is \", len(test_docs))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The categories (classes) of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create counter to summarize\n",
    "categories = []\n",
    "file_count = []\n",
    "np.random.seed(42)\n",
    "# count each tag's number of documents\n",
    "for i in reuters.categories(reuters.fileids()):\n",
    "    \"\"\"print(\"$ There are {} documents included in topic \\\"{}\\\"\"\n",
    "          .format(len(reuters.fileids(i)), i))\"\"\"\n",
    "    file_count.append(len(reuters.fileids(i)))\n",
    "    categories.append(i)\n",
    "\n",
    "# create a dataframe out of the counts\n",
    "allCategories  = pd.DataFrame(\n",
    "    {'categories': categories, \"file_count\": file_count}) \\\n",
    "    .sort_values('file_count', ascending=False)\n",
    "allCategories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data using a number of classes k=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T22:29:46.281523Z",
     "start_time": "2018-11-21T22:29:46.277887Z"
    }
   },
   "outputs": [],
   "source": [
    "# determines number of categories.\n",
    "k=20\n",
    "# Select documents that only contains top two labels with most documents\n",
    "category_filter =allCategories.iloc[0:k, 0].values.tolist()\n",
    "print(category_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-21T22:29:49.397750Z",
     "start_time": "2018-11-21T22:29:47.891040Z"
    }
   },
   "outputs": [],
   "source": [
    "#load examples for top K classes\n",
    "def loadReutersTrainTestTopFiltered(category_filter):\n",
    "    # select fileid with the category filter\n",
    "    np.random.seed(42)\n",
    "    documents = reuters.fileids()\n",
    "\n",
    "    doc_list = np.array(reuters.fileids(category_filter))\n",
    "    doc_list = doc_list[doc_list != 'training/3267']\n",
    "\n",
    "    train_docs_id = list(filter(lambda doc: doc.startswith(\"train\"), doc_list))\n",
    "    test_docs_id = list(filter(lambda doc: doc.startswith(\"test\"), doc_list))\n",
    "    #Input text\n",
    "    train_docs = [reuters.raw(doc_id) for doc_id in train_docs_id]\n",
    "    test_docs = [reuters.raw(doc_id) for doc_id in test_docs_id]\n",
    "    #Categories \n",
    "    train_target_names = [reuters.categories  (doc_id) for doc_id in train_docs_id]\n",
    "    test_target_names = [reuters.categories  (doc_id) for doc_id in test_docs_id]\n",
    "    #remove labels from each example that have not been selected\n",
    "    # ['earn', 'acq', 'money-fx', 'grain', 'crude', 'trade', 'interest', 'ship', 'wheat', 'corn']\n",
    "    # E.g., ['Japanese Anime',  'earn', 'acq']  --> ['earn', 'acq'] \n",
    "    transformedTags = []\n",
    "    for tags in train_target_names:\n",
    "        tagsTmp=[]\n",
    "        for tag in tags:\n",
    "            if tag in category_filter:\n",
    "                tagsTmp.append(tag)\n",
    "        transformedTags.append(tagsTmp)\n",
    "    train_target_namesK = transformedTags  \n",
    "    \n",
    "    transformedTags = []\n",
    "    for tags in test_target_names:\n",
    "        tagsTmp=[]\n",
    "        for tag in tags:\n",
    "            if tag in category_filter:\n",
    "                tagsTmp.append(tag)\n",
    "        transformedTags.append(tagsTmp)\n",
    "    test_target_namesK = transformedTags    \n",
    "   \n",
    "    return(train_docs, test_docs, train_target_namesK, test_target_namesK)\n",
    "\n",
    "train_docs, test_docs, train_target_names, test_target_names = loadReutersTrainTestTopFiltered(category_filter)\n",
    "print(\"Number of train docs is \", len(train_docs))\n",
    "print(\"Number of test docs is \", len(test_docs))\n",
    "mlb = MultiLabelBinarizer(classes=category_filter)\n",
    "Y_train = mlb.fit_transform(train_target_names)\n",
    "Y_test = mlb.fit_transform(test_target_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Defining the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pipeline combining the text feature extractor CountVectorizer\n",
    "# using cachedStopWords as stop_words, TfidfTransformer() and \n",
    "# MultiOutputClassifier() with SGDClassifier() as a parameter, and max_iter=50 as parameter within SGDClassifier() \n",
    "#==================================================#\n",
    "#               Your code starts here              #\n",
    "#==================================================#\n",
    "pipeline = Pipeline([\n",
    "    ('vect', ),\n",
    "    ('tfidf', ), \n",
    "    ('clf', )),])\n",
    "\n",
    "#==================================================#\n",
    "#               Your code ends here                #\n",
    "#               Please don't add code below here   #\n",
    "#==================================================#\n",
    "pipeline.named_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T01:55:28.281211Z",
     "start_time": "2018-11-18T01:46:45.490568Z"
    }
   },
   "outputs": [],
   "source": [
    "#Multi-labels per example evaluation\n",
    "def evaluate(test_labels, predictions):\n",
    "    precision = precision_score(test_labels, predictions, average='micro')\n",
    "    recall = recall_score(test_labels, predictions, average='micro')\n",
    "    f1 = f1_score(test_labels, predictions, average='micro')\n",
    "    print(\"Micro-average quality numbers\")\n",
    "    print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "\n",
    "    # Complete the following code to calculate the\n",
    "    # precision, recall and F1 score using the macro approach\n",
    "    #==================================================#\n",
    "    #               Your code starts here              #\n",
    "    #==================================================#\n",
    "    precision = precision_score()\n",
    "    recall = recall_score()\n",
    "    f1 = f1_score()\n",
    "    #==================================================#\n",
    "    #               Your code ends here                #\n",
    "    #               Please don't add code below here   #\n",
    "    #==================================================#\n",
    "    print(\"Macro-average quality numbers\")\n",
    "    print(\"Precision: {:.4f}, Recall: {:.4f}, F1-measure: {:.4f}\".format(precision, recall, f1))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing gridsearch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: This cell might take more than an hour to run.\n",
    "# uncommenting more parameters will give better exploring power but will\n",
    "# increase processing time in a combinatorial way\n",
    "# Parameters of the estimators in the pipeline can be accessed using the <estimator>__<parameter> syntax:\n",
    "parameters = { #listed in the form of \"step__parameter\", e.g, clf__penalty\n",
    "    #'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    #'vect__max_features': (None, 200,500), \n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams (single words) or bigrams (or sequence of words of length 2)\n",
    "    #'tfidf__use_idf': (True, False),\n",
    "    #'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__estimator__alpha': (0.001, 0.01, .1),        ## access parameters for the estimator inside\n",
    "    'clf__estimator__penalty': ('l1', 'l2', 'elasticnet'),  ## the MultioutputClassifier step by using\n",
    "    'clf__estimator__loss': ('perceptron', 'log')     ## step__MultioutputClassierParameter__EstimatorParameter\n",
    "}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected\n",
    "    # block\n",
    "\n",
    "    # find the best parameters for both the feature extraction and the\n",
    "    # classifier\n",
    "    # n_jobs=-1 means that the computation will be dispatched on all the CPUs of the computer.\n",
    "    #\n",
    "    # By default, the GridSearchCV uses a 3-fold cross-validation. However, if it \n",
    "    #            detects that a classifier is passed, rather than a regressor, it uses a stratified 3-fold.\n",
    "    cv = KFold(n_splits=3, random_state=42, shuffle=True)\n",
    "    grid_search = GridSearchCV(pipeline, parameters, cv=cv, n_jobs=-2, verbose=1, scoring=\"f1_micro\", return_train_score=True)\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)\n",
    "    t0 = time()\n",
    "    grid_search.fit(train_docs, Y_train)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "    #print(\"grid_search.cv_results_\", grid_search.cv_results_)\n",
    "    #estimator : estimator object. This is assumed to implement the scikit-learn estimator interface.  \n",
    "    #            Either estimator needs to provide a score function, or scoring must be passed.\n",
    "    #Accuracy is the default for classification; feel free to change this to precision, recall, fbeta\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        \n",
    "    #Test on Heldlout test set\n",
    "    preds = grid_search.best_estimator_.predict(test_docs)\n",
    "    print(\"--------------------------------------------------------------------\")\n",
    "    evaluate(Y_test, preds)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mean_train_score\tand mean_test_score\n",
    "the gridsearch attribute of `cv_results_`  `mean_test_score` is calculated as the average of the test scores of each cross validation fold. Since in this case we are using `\"f1_micro\"`as as scoring metric. Each `mean_test_score` is the mean of the 3 (`n_splits=3`) `f1_micro scores`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "results = pd.DataFrame(grid_search.cv_results_).loc[:, ['mean_test_score','params','mean_fit_time','mean_score_time']].sort_values(by='mean_test_score', ascending=False)\n",
    "results.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reuters Classification with SVM\n",
    "### Defining the pipeline for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "# Define a pipeline combining the text feature extractor CountVectorizer\n",
    "# using cachedStopWords as stop_words, TfidfTransformer() and \n",
    "# MultiOutputClassifier() with SVC() as a parameter, and max_iter=50 as paramter within SVC()\n",
    "#==================================================#\n",
    "#               Your code starts here              #\n",
    "#==================================================#\n",
    "pipeline = Pipeline([\n",
    "    ('vect', ),\n",
    "    ('tfidf', ), \n",
    "    ('svm', )),])\n",
    "\n",
    "#==================================================#\n",
    "#               Your code ends here                #\n",
    "#               Please don't add code below here   #\n",
    "#==================================================#\n",
    "pipeline.named_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing gridsearch for SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# uncommenting more parameters will give better exploring power but will\n",
    "# increase processing time in a combinatorial way\n",
    "# Parameters of the estimators in the pipeline can be accessed using the <estimator>__<parameter> syntax:\n",
    "parameters = { #listed in the form of \"step__parameter\", e.g, clf__penalty\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams (single words) or bigrams (or sequence of words of length 2)\n",
    "    #'tfidf__use_idf': (True, False),\n",
    "    #'tfidf__norm': ('l1', 'l2'),\n",
    "    'svm__estimator__C': (.1, 1, 10),        ## access parameters for the estimator inside\n",
    "    'svm__estimator__kernel': ('linear', 'poly'),  ## the MultioutputClassifier step by using\n",
    "    'svm__estimator__degree': (1,2,3)     ## step__MultioutputClassierParameter__EstimatorParameter\n",
    "}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected\n",
    "    # block\n",
    "\n",
    "    # find the best parameters for both the feature extraction and the\n",
    "    # classifier\n",
    "    # n_jobs=-1 means that the computation will be dispatched on all the CPUs of the computer.\n",
    "    #\n",
    "    # By default, the GridSearchCV uses a 3-fold cross-validation. However, if it \n",
    "    #            detects that a classifier is passed, rather than a regressor, it uses a stratified 3-fold.\n",
    "    cv = KFold(n_splits=3, random_state=42, shuffle=True)\n",
    "    grid_search = GridSearchCV(pipeline, parameters, cv=cv, n_jobs=-2, verbose=1, scoring=\"f1_micro\", return_train_score=True)\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)\n",
    "    t0 = time()\n",
    "    grid_search.fit(train_docs, Y_train)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "    #print(\"grid_search.cv_results_\", grid_search.cv_results_)\n",
    "    #estimator : estimator object. This is assumed to implement the scikit-learn estimator interface.  \n",
    "    #            Either estimator needs to provide a score function, or scoring must be passed.\n",
    "    #Accuracy is the default for classification; feel free to change this to precision, recall, fbeta\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    # Complete the code below to get the parameters of your best model based on gridsearch\n",
    "    #==================================================#\n",
    "    #               Your code starts here              #\n",
    "    #==================================================#\n",
    "    best_parameters = \n",
    "    #==================================================#\n",
    "    #               Your code ends here                #\n",
    "    #               Please don't add code below here   #\n",
    "    #==================================================#\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        \n",
    "    #Test on Heldlout test set\n",
    "    preds = grid_search.best_estimator_.predict(test_docs)\n",
    "    print(\"--------------------------------------------------------------------\")\n",
    "    evaluate(Y_test, preds)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "results = pd.DataFrame(grid_search.cv_results_).loc[:, ['mean_train_score','mean_test_score','params','mean_fit_time','mean_score_time']].sort_values(by='mean_test_score', ascending=False)\n",
    "results.head(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Optional Task] Multiclass perceptron: classification+training\n",
    "\n",
    "Like most other techniques for training linear classifiers, the perceptron generalizes naturally to multiclass classification. Here, the input ${\\displaystyle x}$  and the output ${\\displaystyle y}$  are drawn from arbitrary sets. A feature representation function ${\\displaystyle f(x,y)}$  maps each possible input/output pair to a finite-dimensional real-valued feature vector. As before, the feature vector is multiplied by a weight vector ${\\displaystyle w}$, but now the resulting score is used to choose among many possible outputs:\n",
    "\n",
    "$${\\displaystyle {\\hat {y}}=\\operatorname {argmax} _{y}f(x,y)\\cdot w.} $$\n",
    "\n",
    "\n",
    "\n",
    "Learning again iterates over the examples, predicting an output for each, leaving the weights unchanged when the predicted output matches the target, and changing them when it does not. \n",
    "\n",
    "Given that the predicted class ${\\hat{y}}$ is different to that actual class $y$:\n",
    "\n",
    "\n",
    "$${\\displaystyle {\\hat {y}}=\\operatorname {argmax} _{y}f(x,y)\\cdot w.} $$\n",
    "\n",
    "the update becomes for each $w_{i,j}$:\n",
    "\n",
    "\n",
    "\n",
    "$\n",
    "\\begin{split}\n",
    "\\operatorname{update}(\\hat{y},y) =\n",
    "\\begin{cases}\n",
    "y_j = y& {w_{i,j}}^{(\\text{next step})} = w_{i,j} + \\eta  x_i\\\\\n",
    "{y}_k = \\hat{y}  & {w_{i,k}}^{(\\text{next step})} = w_{i,k} - \\eta  x_i\n",
    "\\end{cases} & \\quad\\quad\n",
    "\\end{split}\n",
    "$\n",
    "\n",
    "The above gradient update step for the multiclass perceptron is as follows:\n",
    "* for every wrong prediction, penalize(reduce) the weights (and perpendicular distance) that got predicted wrongly and \n",
    "* increase the weights of the class that was the target, that we failed to predict correctly.\n",
    "\n",
    "\n",
    "This multiclass feedback formulation reduces to the original perceptron when ${\\displaystyle x}$  is a real-valued vector, ${\\displaystyle y}$ is chosen from ${\\displaystyle \\{0,1\\}} $, and ${\\displaystyle f(x,y)=yx} $.\n",
    "\n",
    "** Perceptron learning rule (weight update) for binary classifier**\n",
    "\n",
    "$\n",
    "{w_{i,j}}^{(\\text{next step})} = w_{i,j} + \\eta (y_j - \\hat{y}_j) x_i\n",
    "$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Optional Task] Complete the following code to build a Multiclass Perceptron algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T01:55:28.292099Z",
     "start_time": "2018-11-18T01:55:28.283256Z"
    }
   },
   "outputs": [],
   "source": [
    "class HomeGrownPerceptron(object):\n",
    "    \"\"\"Perceptron classifier.\n",
    "\n",
    "    Parameters\n",
    "    ------------\n",
    "    eta : float\n",
    "      Learning rate (between 0.0 and 1.0)\n",
    "    n_iter : int\n",
    "      Passes over the training dataset.\n",
    "    random_state : int\n",
    "      Random number generator seed for random weight\n",
    "      initialization.\n",
    "\n",
    "    Attributes\n",
    "    -----------\n",
    "    w_ : 1d-array\n",
    "      Weights after fitting.\n",
    "    errors_ : list\n",
    "      Number of misclassifications (updates) in each epoch.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, eta=0.01, n_iter=50, random_state=1):\n",
    "        self.eta = eta\n",
    "        self.n_iter = n_iter\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like}, shape = [n_samples, n_features]\n",
    "          Training vectors, where n_samples is the number of samples and\n",
    "          n_features is the number of features.\n",
    "        y : array-like, shape = [n_samples]\n",
    "          Target values.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "\n",
    "        \"\"\"\n",
    "        rgen = np.random.RandomState(self.random_state)\n",
    "        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=1 + X.shape[1])\n",
    "        self.errors_ = []\n",
    "\n",
    "        for _ in range(self.n_iter):\n",
    "            errors = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                update = self.eta * (target - self.predict(xi))\n",
    "                self.w_[1:] += update * xi\n",
    "                self.w_[0] += update\n",
    "                errors += int(update != 0.0)\n",
    "            self.errors_.append(errors)\n",
    "        return self\n",
    "\n",
    "    def net_input(self, X):\n",
    "        \"\"\"Calculate net input\"\"\"\n",
    "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step\"\"\"\n",
    "        return np.where(self.net_input(X) >= 0.0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T01:55:28.304411Z",
     "start_time": "2018-11-18T01:55:28.293928Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class MulticlassHomeGrownPerceptron(HomeGrownPerceptron):\n",
    "    \"\"\" Multiclass HomeGrown Perceptron classifier.\"\"\"\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit training data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like}, shape = [n_samples, n_features]\n",
    "          Training vectors, where n_samples is the number of samples and\n",
    "          n_features is the number of features.\n",
    "        y : array-like, shape = [n_samples]\n",
    "          Target values.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "\n",
    "        \"\"\"\n",
    "        n_classes = np.unique(y).size\n",
    "        rgen = np.random.RandomState(self.random_state)\n",
    "        self.w_ = rgen.normal(loc=0.0, scale=0.01, size=(n_classes, 1 + X.shape[1]))\n",
    "        self.errors_ = []\n",
    "\n",
    "        for _ in range(self.n_iter):\n",
    "            errors = 0\n",
    "            for xi, target in zip(X, y):\n",
    "                predicted = self.predict(xi)\n",
    "                if target != predicted:  #Mistake\n",
    "                    # Complete the following code to \n",
    "                    # Reduce the score of the incorrectly predicted class\n",
    "                    #==================================================#\n",
    "                    #               Your code starts here              #\n",
    "                    #==================================================#\n",
    "                    self.w_[predicted,1:] = \n",
    "                    self.w_[predicted,0] = \n",
    "                    #==================================================#\n",
    "                    #               Your code ends here                #\n",
    "                    #               Please don't add code below here   #\n",
    "                    #==================================================#\n",
    "                    #increase the score of the true class\n",
    "                    self.w_[target,1:] += self.eta * xi\n",
    "                    self.w_[target,0] += self.eta\n",
    "                    errors += 1\n",
    "            self.errors_.append(errors)\n",
    "        return self\n",
    "\n",
    "    def net_input(self, X):\n",
    "        \"\"\"Calculate net input\"\"\"\n",
    "        return np.dot(X, self.w_[:,1:].T) + self.w_[:,0].T\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Return class label after unit step\"\"\"\n",
    "        if X.ndim == 1:\n",
    "            return np.argmax(self.net_input(X))\n",
    "        else:\n",
    "            return np.argmax(self.net_input(X), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T01:55:28.313237Z",
     "start_time": "2018-11-18T01:55:28.306989Z"
    }
   },
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "data = wine.data\n",
    "targets = wine.target\n",
    "target_names = wine.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data. Confirm split and check class distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T01:55:28.323419Z",
     "start_time": "2018-11-18T01:55:28.315547Z"
    }
   },
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(data, targets, test_size=.2, shuffle=True, random_state=42)\n",
    "\n",
    "print('Train: {}   {}'.format(Xtrain.shape, ytrain.shape))\n",
    "print('Test: {}   {}'.format(Xtest.shape, ytest.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T01:55:28.332874Z",
     "start_time": "2018-11-18T01:55:28.325792Z"
    }
   },
   "outputs": [],
   "source": [
    "vals = np.unique(ytrain)\n",
    "print('Train data')\n",
    "for v in vals:\n",
    "    print('{}: {}'.format(target_names[v], np.sum(ytrain == v)))\n",
    "    \n",
    "print('\\nTest data')\n",
    "for v in vals:\n",
    "    print('{}: {}'.format(target_names[v], np.sum(ytest == v)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit data\n",
    "Fit homegrown model and generate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T01:55:28.450499Z",
     "start_time": "2018-11-18T01:55:28.340344Z"
    }
   },
   "outputs": [],
   "source": [
    "mcp = MulticlassHomeGrownPerceptron()\n",
    "# fit the multiclass homegrown perceptron to the training data\n",
    "# Predict classes for training data and test data\n",
    "#==================================================#\n",
    "#               Your code starts here              #\n",
    "#==================================================#\n",
    "mcp.fit()\n",
    "ytrain_preds = \n",
    "ytest_preds = \n",
    "#==================================================#\n",
    "#               Your code ends here                #\n",
    "#               Please don't add code below here   #\n",
    "#==================================================#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "Calculate metrics using micro and macro average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-18T01:55:28.480876Z",
     "start_time": "2018-11-18T01:55:28.456247Z"
    }
   },
   "outputs": [],
   "source": [
    "y = {'Train': [ytrain, ytrain_preds], 'Test': [ytest, ytest_preds]}\n",
    "results = pd.DataFrame(columns = ['Model', 'Accuracy', 'Precision Micro ', 'Precision Macro'])\n",
    "for k in y.keys():\n",
    "    results.loc[len(results)] = ['Homegrown Multiclass Perceptron ({})'.format(k),\n",
    "               round(accuracy_score(y[k][0], y[k][1]),5), \n",
    "               round(precision_score(y[k][0], y[k][1], average='micro'),5),\n",
    "               round(precision_score(y[k][0], y[k][1], average='macro'),3)]  \n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Optional Task]Support Vector Machine classifiers in PyTorch\n",
    "This question focuses on implementing a linear Support Vector Machine classifier for a binary   classification problem. The basic idea behind a binary linear SVM is to find a separating hyperplane for two categories. Additionally, to make the model as generic as possible, SVM tries to make the margin separating the two sets of points as wide as possible. When the data are not linearly separable, linear SVMs  can be exteneded to  non-linear SVMs  using kernels and  the kernel trick.\n",
    "\n"
   ]
  },
  {
   "attachments": {
    "6099cef6-3bf8-4b5b-a87a-538c3b4d09d4.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![download.png](attachment:6099cef6-3bf8-4b5b-a87a-538c3b4d09d4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coding up an linear SVM  in Pytorch is pretty straightforward as we can use the  autograd and optim packages. \n",
    "\n",
    "\n",
    "https://github.com/nikhilraghava/PyTorch-SVM/blob/master/SVM%20-%20PyTorch.ipynb\n",
    "\n",
    "\n",
    "This is pretty straighforward, and has been done before by <a href=\"http://deeplearning.net/wp-content/uploads/2013/03/dlsvm.pdf\">Tang in this 2013 paper</a>.</p>\n",
    "<p>The separating hyperplane is defined by the <strong>wx - b = 0</strong> equation, where <strong>w</strong> is the normal vector and <strong>b</strong> is a scalar offset. <strong>w</strong>âs dimendionality is however many features we have. Additionally, we will try to place the plane in such a way that it falls halfway between the two classes, so that, if possible, there are no points behind the <strong>wx - b = Â±1</strong> lines (see first image). For each training point <strong>x</strong>, we want <strong>wx - b &gt; 1</strong> if <strong>x</strong> is in the <strong>+1</strong> class, <strong>wx - b &lt; -1</strong> if <strong>x</strong> is in the <strong>-1</strong> class (we re-label classes to <strong>Â±1</strong>). Calling the labels <strong>y</strong>, we can multiply both equations to get the same thing: <strong>y ( wx - b) &gt; 1</strong>, or <strong>1 - y ( wx - b ) &lt; 0</strong>.</p>\n",
    "<p>So our constraint is for these expressions to be less than zero for each training point. If itâs positive, thatâs âbadâ. If itâs negative, we donât really care how negative it is. This leads to the loss function: <strong>â max[0, 1 - y ( wx - b ) ]</strong>. To make it optimizer friendly, we square it: <strong>â max[0, 1 - y ( wx - b ) ]Â²</strong>.</p>\n",
    "<p>There is a caveat though. What if the training points overlap? Or, there is just a few points which would cause the separating hyperplaneâs margin to be very narrow? As the first picture shows, the width of the margin is <strong>2/|w|</strong>, we also want to maximize this, or, minimize <strong>|w|/2</strong>, so the model generalizes better. So the full loss function is: <strong>|w|/2 + C â max[0, 1 - y ( wx - b ) ]Â²</strong>. <strong>C</strong> is an important hyperparameter, it sets the importance of separating all the points and pushing them outside the margin <em>versus</em> getting a wide margin.</p>\n",
    "<h2>Pytorch code</h2>\n",
    "<p>First, letâs get the Iris data. The easiest is to get it from SciKit-Learn, which comes with a bunch of standard datasets. We can use <a href=\"https://matplotlib.org/api/pyplot_api.html\">pyplot</a> to visualize Irisâs 4 features and the 3 species:</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install pytorch\n",
    "!conda install -y pytorch torchvision -c pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## PyTorch Loss for CXE: expected inputs explained\n",
    "\n",
    "- `torch.nn.functional.binary_cross_entropy` takes logistic sigmoid values as inputs\n",
    "- `torch.nn.functional.binary_cross_entropy_with_logits` takes logits as inputs \n",
    "- `torch.nn.functional.cross_entropy` takes logits as inputs (performs `log_softmax` internally)\n",
    "- `torch.nn.functional.nll_loss` is like `cross_entropy` but takes log-probabilities (log-softmax) values as inputs\n",
    "\n",
    "### L1Loss \n",
    "L1Loss is  a loss criterion that measures the mean absolute error (MAE) between each element in the prediction for y  and the target y .For implementation details L1Loss in PyTorch please see [here](https://pytorch.org/docs/stable/generated/torch.nn.L1Loss.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Iris Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Changing the following to sklearn.datasets from datasets.samples_generator\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "import torch\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# load data\n",
    "iris = load_iris()\n",
    "\n",
    "X = iris['data'][:,:2]\n",
    "y = iris['target']\n",
    "y[y==0] = -1  #make it a binary problem\n",
    "y[y==2] = 1   #make it a binary problem\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\"\"\"#Blobs data\n",
    "X, Y = make_blobs(n_samples=500, centers=2, random_state=0, cluster_std=0.4)\n",
    "Y[np.where(Y == 0)] = -1\n",
    "in_features = X.shape[1]\n",
    "\n",
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\"\"\"\n",
    "# convert numpy arrays to tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "y_train_tensor = torch.FloatTensor(y_train)\n",
    "y_test_tensor = torch.FloatTensor(y_test)\n",
    "\n",
    "# create TensorDataset\n",
    "X_train_ds = torch.utils.data.TensorDataset(X_train_tensor, y_train_tensor)\n",
    "X_test_ds = torch.utils.data.TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# create dataloader\n",
    "batch_size = 16\n",
    "train_loader = torch.utils.data.DataLoader(X_train_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(X_test_ds, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "pd.DataFrame(np.c_[X_test, y_test], columns=iris.feature_names[:2]+[\"Class\"]).plot.scatter(x='sepal length (cm)',  \n",
    "                                                                                           y='sepal width (cm)', \n",
    "                                                                                           title =\"Iris TEST  Data\",\n",
    "                                                                                           #color=y_test, \n",
    "                                                                                           c=y_test, cmap=\"brg\",colorbar=False,\n",
    "                                                                                           marker=\"o\" , linestyle='None')\n",
    "plt.grid()           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a SVM Net, a single-layered fully connected neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "#########################################################\n",
    "# Soft SVM loss function is \n",
    "#\n",
    "#       Minimize 1/2 ð^ðð+ ðâ (i in 0:n) [ððð¥(0, 1âð_ð^ððð¦_ð )] \n",
    "#\n",
    "## Apply L2 regularization using the weight_decay param of optim.SGD or optim.ADAM\n",
    "#   1:     weight_decay (float, optional) â weight decay (L2 penalty) (default: 0)\n",
    "#   2:     or just code it up by oneself as follows:\n",
    "\n",
    "#########################################################\n",
    "## Apply L2 regularization CASE 1 of 2 (weight decay) manually\n",
    "# loss = F.binary_cross_entropy(out, y_train_tensor, reduction='sum')\n",
    "# loss = loss + 0.5 * LAMBDA * torch.mm(model.out_layer.weight,\n",
    "#                                      model.out_layer.weight.t())\n",
    "\n",
    "# note that PyTorch also regularizes the bias, hence, if we want\n",
    "# to reproduce the behavior of SGD's \"weight_decay\" param, we have to add\n",
    "# the bias term as well: \n",
    "# loss = loss + 0.5 * LAMBDA * model.out_layer.bias**2\n",
    "\n",
    "#-------------------------------------------------------\n",
    "## Apply L2 regularization CASE 2 of 2 (weight decay) via optim package functions\n",
    "LAMBDA = 2\n",
    "weight_decay=LAMBDA\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, weight_decay=LAMBDA)  # SGD optimizer\n",
    "\n",
    "# Sets the module in training mode.\n",
    "# This has any effect only on certain modules. See documentations of particular modules for details of \n",
    "# their behaviors in training/evaluation mode, if they are affected, e.g. Dropout, BatchNorm, etc.\n",
    "model.train()  # The SVM model is a subclass of the nn.Module, so it inherits the train method (not necessary here for svms)\n",
    "# for more info on torch.clamp see https://pytorch.org/docs/stable/generated/torch.clamp.html \n",
    "loss = 0.5 torch.mean(torch.clamp(1 - output * y, min=0))  # hinge loss\n",
    "loss = loss + 0.5 * LAMBDA * torch.mm(model.out_layer.weight,\n",
    "                                      model.out_layer.weight.t())\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss= 3\n",
    "sss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class SVM(nn.Module):\n",
    "    \"\"\"\n",
    "    A binary Linear Support Vector Machine\n",
    "    Support Vector Machine (SVM) is a subclass of the nn.Module class and to initialize the SVM, \n",
    "    call the base class' init function. the  forward method applies a linear transformation \n",
    "    to the incoming data: y = xw + b via a __call__ method in the parent class.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        super().__init__()                                   # Call the init function of nn.Module\n",
    "        self.out_layer = nn.Linear(num_inputs, num_outputs)  # Add a prediction Linear layer XW + b\n",
    "        \n",
    "    def forward(self, x):\n",
    "        fwd = self.out_layer(x)  # Forward pass\n",
    "        return fwd #perpendiculat distances\n",
    "\n",
    "def binary_linear_SVM_loss(y_hat, y, C = 0.10, model = model):\n",
    "    \"\"\" given a training set with m rows and n columns, learn a linear binary SVM \n",
    "        with the corresponding hinge loss and regularizatin terms: \n",
    "    \n",
    "             minimize  C/2 * wTw + lamdba/m x  â_i max(0, 1 - y_i (XW + b))\n",
    "             \n",
    "    \"\"\"\n",
    "    #==================================================#\n",
    "    #               Your code starts here              #\n",
    "    #==================================================#\n",
    "    #########################################################\n",
    "    data_loss = \n",
    "    weights = \n",
    "    reg_loss = \n",
    "    reg_loss = \n",
    "    #-------------------------------------------------------\n",
    "    #==================================================#\n",
    "    #               Your code ends here                #\n",
    "    #               Please don't add code below here   #\n",
    "    #==================================================#\n",
    "\n",
    "    return data_loss + C* reg_loss/2.0\n",
    "\n",
    "\n",
    "class SVM_Loss(nn.modules.Module):    \n",
    "    def __init__(self):\n",
    "        super(SVM_Loss,self).__init__()\n",
    "    def forward(self, outputs, labels): \n",
    "        \"\"\"Data loss term (notice that the regularization is missing)\"\"\"\n",
    "        return torch.sum(torch.clamp(1 - outputs.squeeze().t()*labels, min=0))/batch_size\n",
    "\n",
    "\n",
    "\n",
    "def train_epoch(epoch, clf, criterion, opt, train_loader):\n",
    "    clf.train() # set model in training mode (need this because of dropout)\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    # dataset API gives us pythonic batching \n",
    "    for batch_id, data in enumerate(train_loader):\n",
    "        inputs, targets = data[0].to(device), data[1].to(device)        \n",
    "        # 1:zero the grad, 2:forward pass, 3:calculate loss,  and 4:backprop!\n",
    "        opt.zero_grad()\n",
    "\n",
    "        outputs = model(inputs) #prediction over the input data\n",
    "        #loss = criterion(clf, preds, target)  #mean loss for this batch\n",
    "        loss = criterion(outputs, targets)  #mean loss for this batch\n",
    "        loss.backward() #calculate nabla_w\n",
    "        loss_history.append(loss.item())\n",
    "        opt.step()  #update W\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        # print statistics\n",
    "        if batch_id % 100 == 0:    # print every 100 mini-batches\n",
    "          print(f\"Epoch {epoch}, batch {batch_id}, batch loss: {np.round(loss.item(),6)}\")\n",
    "          running_loss = 0.0\n",
    "    return clf\n",
    "\n",
    "#from IPython.core.debugger import Pdb as pdb;    pdb().set_trace() #breakpoint; dont forget to quit\n",
    "def evaluate_model(epoch, clf, criterion, opt, data_loader, tag = \"Test\"):\n",
    "    clf.eval() # set model in inference mode (need this because of dropout)\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    overall_loss = 0.0\n",
    "    for i,data in enumerate(data_loader):\n",
    "        inputs, targets = data[0].to(device), data[1].to(device)                \n",
    "        outputs = clf(inputs)\n",
    "        # torch.max() Returns a namedtuple (values, indices) where values is the maximum value of each row of the \n",
    "        # input tensor in the given dimension dim. And indices is the index location of each maximum value found (argmax).\n",
    "        #_, predicted_classes = torch.max(outputs.data, 1)  # get the index of the max perp distance\n",
    "        predicted_classes = torch.where(outputs.squeeze()>=0, 1, 0)\n",
    "        target_class = torch.where(targets == -1, 0, 1) #swap -1 labels to 0\n",
    "        correct += (predicted_classes == target_class).sum().item()\n",
    "        \n",
    "        #loss = criterion(clf, outputs, targets)           # compute loss value\n",
    "        loss = criterion(outputs, targets)  #mean loss for this batch\n",
    "        loss_this_iter = loss.cpu().detach().numpy() # send loss value to CPU to save to logs\n",
    "        overall_loss += (loss_this_iter * inputs.size(0))  # compute total loss to save to logs\n",
    "        count += len(inputs)  #inputs.size(0)\n",
    "\n",
    "        # compute mean loss\n",
    "    overall_loss /= float(count)\n",
    "\n",
    "    accuracy = 100. * correct / count\n",
    "    acc_history.append(accuracy)\n",
    "    print(f\"{tag} {epoch} set: Average loss: {overall_loss:.6f}, Accuracy: {correct}/{count} ({accuracy:.0f}%)\")\n",
    "    return accuracy\n",
    "\n",
    "loss_history = []\n",
    "acc_history = []\n",
    "# adding in_features from 8.1.1\n",
    "in_features = X.shape[1]\n",
    "model = SVM(in_features, 1)  # SVM model\n",
    "for name, parameter in model.named_parameters(): # or param in model.parameters():\n",
    "    print(f\"SVM: {name}, type:{type(parameter)}, size:{parameter.size()}\")\n",
    "print(\"_\"*50)\n",
    "print(f\"model.out_layer.weight: {model.out_layer.weight}\")\n",
    "print(f\"model.out_layer.bias:   {model.out_layer.bias}\")\n",
    "#nn.CrossEntropyLoss() #class\n",
    "\n",
    "#use loss function (as opposed to the loss class; see below)\n",
    "#binary_linear_SVM_loss = binary_linear_SVM_loss\n",
    "opt = optim.SGD(model.parameters(), lr=0.01, momentum=0.5) #L2 Regularization term mixing coefficient is part of the loss function\n",
    "\n",
    "#loss class\n",
    "binary_linear_SVM_loss = SVM_Loss()\n",
    "#binary_linear_SVM_loss = nn.HingeEmbeddingLoss(1, reduction=\"mean\")\n",
    "opt = optim.SGD(model.parameters(), lr=0.01, momentum=0.5, weight_decay=0.1) #L2 Regularization term mixing coefficient\n",
    "    \n",
    "\n",
    "for epoch in range(20):\n",
    "    #print(\"Epoch %d\" % epoch)\n",
    "    clf = train_epoch(epoch, model, binary_linear_SVM_loss, opt, train_loader)\n",
    "    if (epoch%10) ==0:\n",
    "        evaluate_model(epoch,    model, binary_linear_SVM_loss, opt, test_loader, tag = \"Validation\")\n",
    "print(\"-\"*50)\n",
    "evaluate_model(    epoch,    model, binary_linear_SVM_loss, opt, test_loader, tag=\"Test\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_SVM_decision_surface(X, Y, model):\n",
    "    W = model.out_layer.weight.squeeze().detach().cpu().numpy()\n",
    "    b = model.out_layer.bias.squeeze().detach().cpu().numpy()\n",
    "\n",
    "    delta = 0.001\n",
    "    x = np.arange(X[:, 0].min(), X[:, 0].max(), delta)\n",
    "    y = np.arange(X[:, 1].min(), X[:, 1].max(), delta)\n",
    "    x, y = np.meshgrid(x, y)\n",
    "    xy = list(map(np.ravel, [x, y]))\n",
    "\n",
    "    z = (W.dot(xy) + b).reshape(x.shape)\n",
    "    z[np.where(z > 1.0)] = 4\n",
    "    z[np.where((z > 0.0) & (z <= 1.0))] = 3\n",
    "    z[np.where((z > -1.0) & (z <= 0.0))] = 2\n",
    "    z[np.where(z <= -1.0)] = 1\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.xlim([X[:, 0].min() + delta, X[:, 0].max() - delta])\n",
    "    plt.ylim([X[:, 1].min() + delta, X[:, 1].max() - delta])\n",
    "    plt.contourf(x, y, z, alpha=0.8, cmap=\"Greys\")\n",
    "    plt.scatter(x=X[:, 0], y=X[:, 1], c=\"black\", s=10)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "display_SVM_decision_surface(X_test, y_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "#removing samples.generator from below\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "\n",
    "def train(X, Y, model, args):\n",
    "    X = torch.FloatTensor(X)\n",
    "    Y = torch.FloatTensor(Y)\n",
    "    N = len(Y)\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=args[\"lr\"])\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(args[\"epoch\"]):\n",
    "        perm = torch.randperm(N)\n",
    "        sum_loss = 0\n",
    "\n",
    "        for i in range(0, N, args[\"batchsize\"]):\n",
    "            x = X[perm[i : i + args[\"batchsize\"]]].to(args[\"device\"])\n",
    "            y = Y[perm[i : i + args[\"batchsize\"]]].to(args[\"device\"])\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x).squeeze()\n",
    "            weight = model.weight.squeeze()\n",
    "\n",
    "            loss = torch.mean(torch.clamp(1 - y * output, min=0))\n",
    "            loss += args[\"c\"] * (weight.t() @ weight) / 2.0\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            sum_loss += float(loss)\n",
    "\n",
    "        print(\"Epoch: {:4d}\\tloss: {}\".format(epoch, sum_loss / N))\n",
    "\n",
    "\n",
    "def visualize(X, Y, model):\n",
    "    W = model.weight.squeeze().detach().cpu().numpy()\n",
    "    b = model.bias.squeeze().detach().cpu().numpy()\n",
    "\n",
    "    delta = 0.001\n",
    "    x = np.arange(X[:, 0].min(), X[:, 0].max(), delta)\n",
    "    y = np.arange(X[:, 1].min(), X[:, 1].max(), delta)\n",
    "    x, y = np.meshgrid(x, y)\n",
    "    xy = list(map(np.ravel, [x, y]))\n",
    "\n",
    "    z = (W.dot(xy) + b).reshape(x.shape)\n",
    "    z[np.where(z > 1.0)] = 4\n",
    "    z[np.where((z > 0.0) & (z <= 1.0))] = 3\n",
    "    z[np.where((z > -1.0) & (z <= 0.0))] = 2\n",
    "    z[np.where(z <= -1.0)] = 1\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.xlim([X[:, 0].min() + delta, X[:, 0].max() - delta])\n",
    "    plt.ylim([X[:, 1].min() + delta, X[:, 1].max() - delta])\n",
    "    plt.contourf(x, y, z, alpha=0.8, cmap=\"Greys\")\n",
    "    plt.scatter(x=X[:, 0], y=X[:, 1], c=\"black\", s=10)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args={\"device\":\"cpu\", \"c\": 0.001, \"lr\": 0.1, \"batchsize\": 16, \"epoch\": 50}\n",
    "    print(args, args.keys())\n",
    "    print(args[\"device\"])\n",
    "    X, Y = make_blobs(n_samples=500, centers=2, random_state=0, cluster_std=0.4)\n",
    "    X = (X - X.mean()) / X.std()\n",
    "    Y[np.where(Y == 0)] = -1\n",
    "\n",
    "    model = nn.Linear(2, 1)\n",
    "    model.to(args[\"device\"])\n",
    "\n",
    "    train(X, Y, model, args)\n",
    "    visualize(X, Y, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Optional Task]Linear SVM for the Binary Classifier and n-ary Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement a linear svm for the binary classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch, implement a linear SVM  for the binary classifier. Benchmark your implementation against the SKLearn implementation using the Iris dataset. In this experiment, learn a Setosa versus the rest. Split the data into train-test based on 70-30 split. Report the accuracy and wall clock times for both your PyTorch implementation and SKLearn implementation on the training and test sets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement experiment table detailing accuracy, execution times for train, test using your PyTorch implementation and SkLearnâs implementation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement a linear svm for a n-ary classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch, implement a linear SVM  for the n-ary classifier. Benchmark your implementation against the SKLearn implementation using the Iris dataset. In this experiment, learn a three class classifier. Split the data into train-test based on 70-30 split. Report the accuracy and wall clock times for both your PyTorch implementation and SKLearn implementation on the training and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement experiment table detailing accuracy, execution times for train, test using your PyTorch implementation and SkLearnâs implementation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "282.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
